{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1408dd3-7acb-4265-89fa-8615e86a6828",
   "metadata": {},
   "source": [
    "# Part II: SDAA-based Sequential Group Recommendations (25 points)\n",
    "\n",
    "**Students:** Oskari Perikangas, Xiaosi Huang  \n",
    "**Date:** November 10, 2025\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522d72d8-af68-4621-a10c-17267828413d",
   "metadata": {},
   "source": [
    "---\n",
    "# Step 1: Design Plan (7 points)\n",
    "SDAA (Satisfaction and Disagreement Aware Aggregation)\n",
    "\n",
    "**State:**\n",
    "- Satisfaction history for each user: `sat_history[u] = [sat_round1, sat_round2, ...]`\n",
    "- Group disagreement trend over previous rounds\n",
    "- Current recommendation round index `j`\n",
    "- Total number of rounds: `μ` (mu)\n",
    "- User rating profiles for initial alpha calculation\n",
    "\n",
    "**Formulas:**\n",
    "$$satO(u, RS) = \\frac{\\sum_{j=1}^{\\mu} sat(u, Gr_j)}{\\mu}$$\n",
    "$$groupDisO(RS) = \\max_{u \\in G} satO(u, RS) - \\min_{u \\in G} satO(u, RS)$$\n",
    "\n",
    "---\n",
    "**Action: SDAA Dynamic Aggregation**\n",
    "\n",
    "- Use SDAA method with practical adaptation:\n",
    "  $$score(G,i,j) = (1 - \\alpha_j) \\times avg\\_score(G,i,j) + \\alpha_j \\times least\\_score(G,i,j)$$\n",
    "  \n",
    "  Where:\n",
    "  - $avg\\_score(G,i,j) = \\frac{\\sum_{u \\in G} p_j(u,i)}{|G|}$ (Average method)\n",
    "  - $least\\_score(G,i,j) = \\min_{u \\in G} p_j(u,i)$ (Least Misery method)\n",
    "\n",
    "- **α_j Calculation**:\n",
    "  - **For round 1**: $\\alpha_1 = 0.1 + 0.5 \\times \\sigma(\\text{user\\_ratings})$\n",
    "    - Uses standard deviation of user average historical ratings\n",
    "    - Maps to range [0.1, 0.6] based on user rating diversity\n",
    "  - **For rounds j > 1**: $\\alpha_j = \\max_{u \\in G} sat(u,Gr_{j-1}) - \\min_{u \\in G} sat(u,Gr_{j-1})$\n",
    "\n",
    "---\n",
    "**Reward:**\n",
    "- Use `R_sd` reward function that balances satisfaction and disagreement:\n",
    "\n",
    "$$R_{sd}(RS^j) = 2 \\times \\frac{groupSatO(RS^j) \\times (1 - groupDisO(RS^j))}{groupSatO(RS^j) + (1 - groupDisO(RS^j))}$$\n",
    "\n",
    "---\n",
    "#### ALGORITHM WORKFLOW:\n",
    "\n",
    "1. **Initialize**: \n",
    "   - Empty satisfaction history for all users\n",
    "   - Calculate initial α₁ based on user rating behavior diversity\n",
    "\n",
    "2. **For each round `j = 1` to `μ`:**\n",
    "   - **If j = 1**: Use calculated initial α based on user diversity\n",
    "   - **If j > 1**: Calculate α_j = max_u sat(u,Gr_{j-1}) - min_u sat(u,Gr_{j-1})\n",
    "   - Generate individual predictions: `p_j(u,i)` for all users and items\n",
    "   - Compute group scores: `score(G,i,j) = (1 - α_j) × avg + α_j × least`\n",
    "   - Select top-k items as group recommendation `Gr_j`\n",
    "   - Calculate round satisfaction: `sat(u,Gr_j)` for each user\n",
    "   - Update state: Append satisfaction scores to history\n",
    "   - Compute reward: `R_sd(RS^j)` for performance tracking\n",
    "\n",
    "3. **Output**: Complete recommendation sequence `RS = {Gr_1, Gr_2, ..., Gr_μ}`\n",
    "\n",
    "#### SATISFACTION CALCULATION:\n",
    "$$sat(u, Gr_j) = \\frac{\\text{avg}(p_j(u, i \\in Gr_j)) - 1}{4}$$\n",
    "\n",
    "**Implementation Approach:**\n",
    "- Normalizes predicted ratings from 1-5 scale to 0-1 satisfaction scale\n",
    "- Provides meaningful satisfaction values for effective SDAA adjustment\n",
    "- Ensures practical computation within reasonable bounds\n",
    "\n",
    "---\n",
    "\n",
    "# Step 2: Explanations and clarifications (6 points)\n",
    "#### Effectiveness evaluation of sequential recommendation methods:\n",
    "\n",
    "**Dynamic Adaptation Demonstrated:**\n",
    "- **Round 1**: Initial α=0.2765 based on user rating diversity\n",
    "- **Round 2**: α=0.4216 based on actual satisfaction disparity from Round 1\n",
    "- **Round 3**: α=0.4415 further adjusted based on Round 2 satisfaction\n",
    "\n",
    "**Fairness Enforcement:**\n",
    "- Increasing α values (0.2765 → 0.4216 → 0.4415) show stronger emphasis on Least Misery\n",
    "- Protects User 599 (lowest satisfaction) while maintaining reasonable group satisfaction\n",
    "\n",
    "**Performance Metrics:**\n",
    "- Final group satisfaction: 0.7285\n",
    "- Final group disagreement: 0.4170  \n",
    "- Average reward across rounds: 0.6486\n",
    "- Balanced performance between satisfaction and fairness\n",
    "\n",
    "**Advantages over Static Methods:**\n",
    "- Adapts to evolving group dynamics across multiple rounds\n",
    "- Automatically balances between Average and Least Misery based on actual user satisfaction\n",
    "- Provides theoretical foundation with practical implementation\n",
    "- Addresses cold-start problem through informed initial α calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd5a821f-5125-4c7c-bb46-3da78be27a0c",
   "metadata": {},
   "source": [
    "# Step 3: Implementation (7 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3875623f-b4af-4139-9be2-9ae39d1a0faf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Loading and Preparing MovieLens Dataset ===\n",
      "Dataset loaded: 610 users, 100836 ratings\n",
      "Sample - User 1 rated 232 movies\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=== Loading and Preparing MovieLens Dataset ===\")\n",
    "\n",
    "# Load ratings data\n",
    "ratings_df = pd.read_csv(\"../data/ml-latest-small/ratings.csv\")\n",
    "\n",
    "# Standardize column names\n",
    "if 'userId' in ratings_df.columns:\n",
    "    ratings_df.rename(columns={'userId': 'user_id', 'movieId': 'item_id'}, inplace=True)\n",
    "\n",
    "# Create user_ratings_dict for efficient access\n",
    "user_ratings_dict = {}\n",
    "for user_id in ratings_df['user_id'].unique():\n",
    "    user_ratings_dict[user_id] = {}\n",
    "    user_data = ratings_df[ratings_df['user_id'] == user_id]\n",
    "    for _, row in user_data.iterrows():\n",
    "        user_ratings_dict[user_id][row['item_id']] = row['rating']\n",
    "\n",
    "print(f\"Dataset loaded: {len(user_ratings_dict)} users, {len(ratings_df)} ratings\")\n",
    "print(f\"Sample - User 1 rated {len(user_ratings_dict[1])} movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50b46be2-f071-43fb-a4e6-bd60e12ab5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_ratings=20: 1297 movies (13.3% of total)\n",
      "min_ratings=30: 882 movies (9.1% of total)\n",
      "min_ratings=50: 450 movies (4.6% of total)\n",
      "min_ratings=75: 236 movies (2.4% of total)\n",
      "min_ratings=100: 138 movies (1.4% of total)\n",
      "User 1: 232 rated movies, 158 overlap with threshold=30 (68.1%), 117 overlap with threshold=50 (50.4%)\n",
      "User 414: 2698 rated movies, 809 overlap with threshold=30 (30.0%), 429 overlap with threshold=50 (15.9%)\n",
      "User 599: 2478 rated movies, 703 overlap with threshold=30 (28.4%), 388 overlap with threshold=50 (15.7%)\n"
     ]
    }
   ],
   "source": [
    "def compare_popularity_thresholds():\n",
    "    \"\"\"Compare different popularity thresholds for movie selection\"\"\"\n",
    "    movie_counts = ratings_df.groupby('item_id').size()\n",
    "    \n",
    "    # Analyze different popularity thresholds\n",
    "    thresholds = [20, 30, 50, 75, 100]\n",
    "    for threshold in thresholds:\n",
    "        count = len(movie_counts[movie_counts >= threshold])\n",
    "        percentage = (count / len(movie_counts)) * 100\n",
    "        print(f\"min_ratings={threshold}: {count} movies ({percentage:.1f}% of total)\")\n",
    "    \n",
    "    # Analyze rating coverage for our test users\n",
    "    test_group = [1, 414, 599]\n",
    "    for user_id in test_group:\n",
    "        user_rated = set(ratings_df[ratings_df['user_id'] == user_id]['item_id'])\n",
    "        popular_30 = set(movie_counts[movie_counts >= 30].index)\n",
    "        popular_50 = set(movie_counts[movie_counts >= 50].index)\n",
    "        \n",
    "        overlap_30 = len(user_rated & popular_30)\n",
    "        overlap_50 = len(user_rated & popular_50)\n",
    "        \n",
    "        print(f\"User {user_id}: {len(user_rated)} rated movies, \"\n",
    "              f\"{overlap_30} overlap with threshold=30 ({overlap_30/len(user_rated)*100:.1f}%), \"\n",
    "              f\"{overlap_50} overlap with threshold=50 ({overlap_50/len(user_rated)*100:.1f}%)\")\n",
    "\n",
    "# Call the comparison function\n",
    "compare_popularity_thresholds()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43264e42-6e8e-4730-8fd7-c6e696b135cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequentialGroupState:\n",
    "    \"\"\"\n",
    "    Manages state for sequential group recommendations according to SQUIRREL framework\n",
    "    Tracks satisfaction history and calculates all required parameters\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, group_users, user_ratings_dict):\n",
    "        self.group_users = group_users\n",
    "        self.user_ratings_dict = user_ratings_dict  # Access to user rating data\n",
    "        self.sat_history = {user: [] for user in group_users}\n",
    "        self.recommendation_history = []\n",
    "        self.current_round = 0\n",
    "        self.initial_alpha_calculated = False\n",
    "        self.initial_alpha = 0.0\n",
    "        \n",
    "    def _calculate_initial_alpha_from_user_diversity(self):\n",
    "        \"\"\"\n",
    "        Calculate initial alpha based on user rating behavior diversity\n",
    "        Uses standard deviation of user average ratings as diversity indicator\n",
    "        \"\"\"\n",
    "        user_avg_ratings = []\n",
    "        \n",
    "        for user_id in self.group_users:\n",
    "            if user_id in self.user_ratings_dict:\n",
    "                ratings = list(self.user_ratings_dict[user_id].values())\n",
    "                if ratings:\n",
    "                    user_avg_ratings.append(np.mean(ratings))\n",
    "        \n",
    "        if len(user_avg_ratings) < 2:\n",
    "            return 0.3  # Default moderate alpha value\n",
    "            \n",
    "        # Calculate standard deviation of user average ratings as diversity metric\n",
    "        rating_std = np.std(user_avg_ratings)\n",
    "        \n",
    "        # Map standard deviation to alpha range [0.1, 0.6]\n",
    "        # Higher rating diversity results in higher initial alpha (more focus on fairness)\n",
    "        initial_alpha = 0.1 + (rating_std / 2.0) * 0.5\n",
    "        return float(max(0.1, min(0.6, initial_alpha)))\n",
    "    \n",
    "    def get_satisfaction_disparity(self):\n",
    "        \"\"\"\n",
    "        Calculate α_j for SDAA method: α_j = max_u sat(u,Gr_{j-1}) - min_u sat(u,Gr_{j-1})\n",
    "        \"\"\"\n",
    "        # For round 1: use initial alpha since no previous round data exists\n",
    "        if self.current_round == 0:\n",
    "            # Start of round 1 - calculate initial alpha based on user diversity\n",
    "            if not self.initial_alpha_calculated:\n",
    "                self.initial_alpha = self._calculate_initial_alpha_from_user_diversity()\n",
    "                self.initial_alpha_calculated = True\n",
    "            return self.initial_alpha\n",
    "        \n",
    "        # For rounds 2 and beyond: use previous round satisfaction data\n",
    "        # When current_round = 1 (after round 1), calculate alpha for round 2\n",
    "        # When current_round = 2 (after round 2), calculate alpha for round 3\n",
    "        \n",
    "        all_prev_sats = []\n",
    "        for user in self.group_users:\n",
    "            # Need at least current_round number of satisfaction entries\n",
    "            # For calculating alpha at round j, the (j-1)th satisfaction values are required\n",
    "            if len(self.sat_history[user]) >= self.current_round:\n",
    "                # The previous round's satisfaction is at index current_round-1\n",
    "                prev_sat = self.sat_history[user][self.current_round - 1]\n",
    "                all_prev_sats.append(prev_sat)\n",
    "        \n",
    "        if not all_prev_sats or len(all_prev_sats) < len(self.group_users):\n",
    "            return 0.0\n",
    "            \n",
    "        min_sat = min(all_prev_sats)\n",
    "        max_sat = max(all_prev_sats)\n",
    "        alpha = max_sat - min_sat\n",
    "        \n",
    "        return float(max(0.0, min(1.0, alpha)))\n",
    "    \n",
    "    def update_round(self, group_recommendations, user_satisfactions):\n",
    "        \"\"\"\n",
    "        Update state after each recommendation round\n",
    "        \"\"\"\n",
    "        self.current_round += 1\n",
    "        self.recommendation_history.append(group_recommendations)\n",
    "        \n",
    "        for user in self.group_users:\n",
    "            if user in user_satisfactions:\n",
    "                self.sat_history[user].append(float(user_satisfactions[user]))\n",
    "    \n",
    "    def calculate_overall_satisfaction(self):\n",
    "        \"\"\"\n",
    "        Calculate satO(u, RS) = average satisfaction across all rounds for each user\n",
    "        satO(u, RS) = Σ_{j=1}^μ sat(u, Gr_j) / μ\n",
    "        \"\"\"\n",
    "        satO = {}\n",
    "        for user in self.group_users:\n",
    "            if self.sat_history[user]:\n",
    "                satO[user] = float(np.mean(self.sat_history[user]))\n",
    "            else:\n",
    "                satO[user] = 0.0\n",
    "        return satO\n",
    "    \n",
    "    def calculate_group_satisfaction(self):\n",
    "        \"\"\"\n",
    "        Calculate groupSatO(RS) = average overall satisfaction across all group members\n",
    "        groupSatO(RS) = Σ_{u∈G} satO(u, RS) / |G|\n",
    "        \"\"\"\n",
    "        satO = self.calculate_overall_satisfaction()\n",
    "        if not satO:\n",
    "            return 0.0\n",
    "        return float(np.mean(list(satO.values())))\n",
    "    \n",
    "    def calculate_group_disagreement(self):\n",
    "        \"\"\"\n",
    "        Calculate groupDisO(RS) = max_u satO(u, RS) - min_u satO(u, RS)\n",
    "        \"\"\"\n",
    "        satO = self.calculate_overall_satisfaction()\n",
    "        if not satO:\n",
    "            return 0.0\n",
    "        return float(max(satO.values()) - min(satO.values()))\n",
    "    \n",
    "    def get_previous_round_satisfactions(self):\n",
    "        \"\"\"\n",
    "        Get satisfaction scores from the previous round\n",
    "        \"\"\"\n",
    "        if self.current_round == 0:\n",
    "            return {user: 0.0 for user in self.group_users}\n",
    "        prev_satisfactions = {}\n",
    "        for user in self.group_users:\n",
    "            if len(self.sat_history[user]) >= self.current_round:\n",
    "                prev_satisfactions[user] = self.sat_history[user][-1]\n",
    "            else:\n",
    "                prev_satisfactions[user] = 0.0\n",
    "        return prev_satisfactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e9cb7e5-9e93-4d09-aa6f-f9bf4e8fb20a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQUIRRELRecommender:\n",
    "    \"\"\"\n",
    "    Complete implementation of SQUIRREL framework with all methods\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, group_users, ratings_df, user_ratings_dict):\n",
    "        # Pass user_ratings_dict to state for initial alpha calculation\n",
    "        self.state = SequentialGroupState(group_users, user_ratings_dict)\n",
    "        self.ratings_df = ratings_df\n",
    "        self.user_ratings_dict = user_ratings_dict\n",
    "        self.popular_movies = self._get_popular_movies()\n",
    "        self.used_movies = set()\n",
    "    \n",
    "    def _get_popular_movies(self, min_ratings=30):\n",
    "        \"\"\"Identify popular movies for reliable predictions\"\"\"\n",
    "        movie_counts = self.ratings_df.groupby('item_id').size()\n",
    "        popular = movie_counts[movie_counts >= min_ratings].index.tolist()\n",
    "        print(f\"Selected {len(popular)} popular movies (min_ratings={min_ratings})\")\n",
    "        return popular\n",
    "    \n",
    "    def _pearson_similarity(self, user1_ratings, user2_ratings, min_common=5):\n",
    "        \"\"\"Calculate Pearson correlation similarity\"\"\"\n",
    "        common_items = set(user1_ratings.keys()) & set(user2_ratings.keys())\n",
    "        \n",
    "        if len(common_items) < min_common:\n",
    "            return 0.0\n",
    "        \n",
    "        ratings1 = [user1_ratings[item] for item in common_items]\n",
    "        ratings2 = [user2_ratings[item] for item in common_items]\n",
    "        \n",
    "        if len(ratings1) < 2:\n",
    "            return 0.0\n",
    "            \n",
    "        mean1 = np.mean(ratings1)\n",
    "        mean2 = np.mean(ratings2)\n",
    "        \n",
    "        numerator = sum((r1 - mean1) * (r2 - mean2) for r1, r2 in zip(ratings1, ratings2))\n",
    "        denom1 = np.sqrt(sum((r1 - mean1) ** 2 for r1 in ratings1))\n",
    "        denom2 = np.sqrt(sum((r2 - mean2) ** 2 for r2 in ratings2))\n",
    "        \n",
    "        if denom1 == 0 or denom2 == 0:\n",
    "            return 0.0\n",
    "            \n",
    "        return float(numerator / (denom1 * denom2))\n",
    "    \n",
    "    def predict_user_rating(self, user_id, item_id, k=10):\n",
    "        \"\"\"Predict user rating using collaborative filtering\"\"\"\n",
    "        if user_id not in self.user_ratings_dict:\n",
    "            return 3.0\n",
    "        \n",
    "        target_ratings = self.user_ratings_dict[user_id]\n",
    "        target_mean = np.mean(list(target_ratings.values()))\n",
    "        \n",
    "        item_ratings = self.ratings_df[self.ratings_df['item_id'] == item_id]\n",
    "        if len(item_ratings) == 0:\n",
    "            return target_mean\n",
    "        \n",
    "        similarities = []\n",
    "        for _, row in item_ratings.iterrows():\n",
    "            neighbor_id = row['user_id']\n",
    "            if neighbor_id != user_id and neighbor_id in self.user_ratings_dict:\n",
    "                sim = self._pearson_similarity(target_ratings, self.user_ratings_dict[neighbor_id])\n",
    "                if sim > 0.1:\n",
    "                    similarities.append((sim, neighbor_id, row['rating']))\n",
    "        \n",
    "        if similarities:\n",
    "            similarities.sort(reverse=True)\n",
    "            top_neighbors = similarities[:k]\n",
    "            \n",
    "            weighted_sum = 0.0\n",
    "            similarity_sum = 0.0\n",
    "            \n",
    "            for sim, neighbor_id, neighbor_rating in top_neighbors:\n",
    "                neighbor_ratings = self.user_ratings_dict[neighbor_id]\n",
    "                neighbor_mean = np.mean(list(neighbor_ratings.values()))\n",
    "                weighted_sum += sim * (neighbor_rating - neighbor_mean)\n",
    "                similarity_sum += sim\n",
    "            \n",
    "            if similarity_sum > 0:\n",
    "                predicted = target_mean + (weighted_sum / similarity_sum)\n",
    "                return float(max(1.0, min(5.0, predicted)))\n",
    "        \n",
    "        item_mean = item_ratings['rating'].mean()\n",
    "        return float(item_mean)\n",
    "    \n",
    "    def calculate_round_satisfaction(self, user_id, group_recommendations):\n",
    "        \"\"\"\n",
    "        Calculate sat(u, Gr_j) with corrected implementation\n",
    "        Instead of using ALL available items (which makes denominator too large),\n",
    "        we normalize based on the maximum possible satisfaction\n",
    "        \"\"\"\n",
    "        if user_id not in self.user_ratings_dict:\n",
    "            return 0.0\n",
    "        \n",
    "        # Calculate predicted ratings for group recommendations\n",
    "        group_predictions = []\n",
    "        for item in group_recommendations:\n",
    "            pred = self.predict_user_rating(user_id, item)\n",
    "            group_predictions.append(pred)\n",
    "        \n",
    "        if not group_predictions:\n",
    "            return 0.0\n",
    "        \n",
    "        # Numerator: average of predicted ratings for group recommendations\n",
    "        numerator = np.mean(group_predictions)\n",
    "        \n",
    "        # Normalize from 1-5 scale to 0-1 scale\n",
    "        satisfaction = (numerator - 1.0) / 4.0\n",
    "        \n",
    "        return float(max(0.0, min(1.0, satisfaction)))\n",
    "    \n",
    "    def calculate_user_disagreement(self, user_id, user_satisfactions):\n",
    "        \"\"\"\n",
    "        Calculate userDis(u, G, Gr_j) = max_{u'∈G} sat(u', Gr_j) - sat(u, Gr_j)\n",
    "        \"\"\"\n",
    "        max_sat = max(user_satisfactions.values())\n",
    "        user_sat = user_satisfactions.get(user_id, 0.0)\n",
    "        return max_sat - user_sat\n",
    "    \n",
    "    def generate_individual_predictions(self, k_candidates=100):\n",
    "        \"\"\"\n",
    "        Generate p_j(u,i) predictions for all users and candidate items\n",
    "        \"\"\"\n",
    "        user_predictions = {}\n",
    "        \n",
    "        for user_id in self.state.group_users:\n",
    "            if user_id not in self.user_ratings_dict:\n",
    "                continue\n",
    "                \n",
    "            # Find unrated popular movies\n",
    "            user_rated = set(self.ratings_df[self.ratings_df['user_id'] == user_id]['item_id'])\n",
    "            user_unrated = [item for item in self.popular_movies \n",
    "                          if item not in user_rated and item not in self.used_movies]\n",
    "            \n",
    "            if len(user_unrated) < k_candidates:\n",
    "                user_unrated = [item for item in self.popular_movies if item not in user_rated]\n",
    "            \n",
    "            # Generate predictions\n",
    "            predictions = {}\n",
    "            for item in user_unrated[:k_candidates]:\n",
    "                pred = self.predict_user_rating(user_id, item)\n",
    "                predictions[item] = pred\n",
    "            \n",
    "            user_predictions[user_id] = predictions\n",
    "        \n",
    "        return user_predictions\n",
    "    \n",
    "    def sdaa_aggregation(self, user_predictions):\n",
    "        \"\"\"\n",
    "        SDAA method: score(G,i,j) = (1 - α_j) * avg_score(G,i,j) + α_j * least_score(G,i,j)\n",
    "        where α_j = max_u sat(u,Gr_{j-1}) - min_u sat(u,Gr_{j-1})\n",
    "        \"\"\"\n",
    "        alpha = self.state.get_satisfaction_disparity()\n",
    "        \n",
    "        print(f\"    SDAA alpha parameter: {alpha:.4f}\")\n",
    "        \n",
    "        all_movies = set()\n",
    "        for predictions in user_predictions.values():\n",
    "            all_movies.update(predictions.keys())\n",
    "        \n",
    "        movie_scores = {}\n",
    "        \n",
    "        for movie in all_movies:\n",
    "            user_scores = []\n",
    "            for predictions in user_predictions.values():\n",
    "                if movie in predictions:\n",
    "                    user_scores.append(predictions[movie])\n",
    "            \n",
    "            if not user_scores:\n",
    "                continue\n",
    "                \n",
    "            avg_score = np.mean(user_scores)\n",
    "            least_score = min(user_scores)\n",
    "            \n",
    "            # SDAA formula\n",
    "            movie_scores[movie] = (1 - alpha) * avg_score + alpha * least_score\n",
    "        \n",
    "        return movie_scores\n",
    "    \n",
    "    def siaa_aggregation(self, user_predictions, b=0.5):\n",
    "        \"\"\"\n",
    "        SIAA method: score(G,i,j) = Σ_{u∈G} w_u,j * p_j(u,i)\n",
    "        where w_u,j = 1 - b * (1 - satO(u, RS_{j-1})) + b * userDis(u, G, Gr_{j-1})\n",
    "        \"\"\"\n",
    "        # Get previous round data\n",
    "        prev_satisfactions = self.state.get_previous_round_satisfactions()\n",
    "        \n",
    "        # Calculate weights for each user\n",
    "        user_weights = {}\n",
    "        for user_id in self.state.group_users:\n",
    "            # Get overall satisfaction up to previous round\n",
    "            satO = 0.0\n",
    "            if self.state.sat_history[user_id]:\n",
    "                satO = np.mean(self.state.sat_history[user_id])\n",
    "            \n",
    "            # Calculate user disagreement from previous round\n",
    "            userDis = self.calculate_user_disagreement(user_id, prev_satisfactions)\n",
    "            \n",
    "            # SIAA weight formula\n",
    "            w_u = 1 - b * (1 - satO) + b * userDis\n",
    "            user_weights[user_id] = max(0.0, w_u)\n",
    "        \n",
    "        print(f\"    SIAA user weights: {user_weights}\")\n",
    "        \n",
    "        # Normalize weights\n",
    "        total_weight = sum(user_weights.values())\n",
    "        if total_weight > 0:\n",
    "            for user_id in user_weights:\n",
    "                user_weights[user_id] /= total_weight\n",
    "        \n",
    "        all_movies = set()\n",
    "        for predictions in user_predictions.values():\n",
    "            all_movies.update(predictions.keys())\n",
    "        \n",
    "        movie_scores = {}\n",
    "        \n",
    "        for movie in all_movies:\n",
    "            weighted_score = 0.0\n",
    "            for user_id, predictions in user_predictions.items():\n",
    "                if movie in predictions:\n",
    "                    weight = user_weights.get(user_id, 0.0)\n",
    "                    weighted_score += weight * predictions[movie]\n",
    "            \n",
    "            if weighted_score > 0:\n",
    "                movie_scores[movie] = weighted_score\n",
    "        \n",
    "        return movie_scores\n",
    "    \n",
    "    def average_aggregation(self, user_predictions):\n",
    "        \"\"\"Standard Average aggregation method\"\"\"\n",
    "        all_movies = set()\n",
    "        for predictions in user_predictions.values():\n",
    "            all_movies.update(predictions.keys())\n",
    "        \n",
    "        movie_scores = {}\n",
    "        \n",
    "        for movie in all_movies:\n",
    "            user_scores = []\n",
    "            for predictions in user_predictions.values():\n",
    "                if movie in predictions:\n",
    "                    user_scores.append(predictions[movie])\n",
    "            \n",
    "            if user_scores:\n",
    "                movie_scores[movie] = np.mean(user_scores)\n",
    "        \n",
    "        return movie_scores\n",
    "    \n",
    "    def least_misery_aggregation(self, user_predictions):\n",
    "        \"\"\"Standard Least Misery aggregation method\"\"\"\n",
    "        all_movies = set()\n",
    "        for predictions in user_predictions.values():\n",
    "            all_movies.update(predictions.keys())\n",
    "        \n",
    "        movie_scores = {}\n",
    "        \n",
    "        for movie in all_movies:\n",
    "            user_scores = []\n",
    "            for predictions in user_predictions.values():\n",
    "                if movie in predictions:\n",
    "                    user_scores.append(predictions[movie])\n",
    "            \n",
    "            if user_scores:\n",
    "                movie_scores[movie] = min(user_scores)\n",
    "        \n",
    "        return movie_scores\n",
    "    \n",
    "    def calculate_reward_rs(self):\n",
    "        \"\"\"\n",
    "        Calculate R_s reward function: focus on satisfaction only\n",
    "        R_s(RS^j) = groupSatO(RS^j)\n",
    "        \"\"\"\n",
    "        return self.state.calculate_group_satisfaction()\n",
    "    \n",
    "    def calculate_reward_rsd(self):\n",
    "        \"\"\"\n",
    "        Calculate R_sd reward function: balance satisfaction and disagreement\n",
    "        R_sd(RS^j) = 2 * (groupSatO(RS^j) * (1 - groupDisO(RS^j))) / \n",
    "                     (groupSatO(RS^j) + (1 - groupDisO(RS^j)))\n",
    "        \"\"\"\n",
    "        groupSatO = self.state.calculate_group_satisfaction()\n",
    "        groupDisO = self.state.calculate_group_disagreement()\n",
    "        \n",
    "        if groupSatO + (1 - groupDisO) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        reward = 2 * (groupSatO * (1 - groupDisO)) / (groupSatO + (1 - groupDisO))\n",
    "        return float(reward)\n",
    "    \n",
    "    def recommend_round(self, k=5, method='sdaa'):\n",
    "        \"\"\"\n",
    "        Generate recommendations for one round using specified method\n",
    "        \"\"\"\n",
    "        user_predictions = self.generate_individual_predictions()\n",
    "        \n",
    "        if not user_predictions:\n",
    "            return [], {user: 0.0 for user in self.state.group_users}\n",
    "        \n",
    "        # Apply specified aggregation method\n",
    "        if method == 'sdaa':\n",
    "            movie_scores = self.sdaa_aggregation(user_predictions)\n",
    "        elif method == 'siaa':\n",
    "            movie_scores = self.siaa_aggregation(user_predictions)\n",
    "        elif method == 'average':\n",
    "            movie_scores = self.average_aggregation(user_predictions)\n",
    "        elif method == 'least_misery':\n",
    "            movie_scores = self.least_misery_aggregation(user_predictions)\n",
    "        else:\n",
    "            movie_scores = self.sdaa_aggregation(user_predictions)\n",
    "        \n",
    "        if not movie_scores:\n",
    "            return [], {user: 0.0 for user in self.state.group_users}\n",
    "        \n",
    "        # Select top-k recommendations\n",
    "        sorted_movies = sorted(movie_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        available_movies = [(movie, score) for movie, score in sorted_movies \n",
    "                          if movie not in self.used_movies]\n",
    "        \n",
    "        if len(available_movies) < k:\n",
    "            available_movies = sorted_movies\n",
    "        \n",
    "        group_recommendations = [movie for movie, score in available_movies[:k]]\n",
    "        self.used_movies.update(group_recommendations)\n",
    "        \n",
    "        # Calculate satisfactions using corrected formula\n",
    "        user_satisfactions = {}\n",
    "        for user_id in self.state.group_users:\n",
    "            sat = self.calculate_round_satisfaction(user_id, group_recommendations)\n",
    "            user_satisfactions[user_id] = sat\n",
    "        \n",
    "        self.state.update_round(group_recommendations, user_satisfactions)\n",
    "        \n",
    "        return group_recommendations, user_satisfactions\n",
    "    \n",
    "    def run_sequential_recommendation(self, num_rounds=3, k=5, method='sdaa', reward_function='rsd'):\n",
    "        \"\"\"\n",
    "        Run complete sequential recommendation process\n",
    "        \"\"\"\n",
    "        print(f\"Starting sequential group recommendation for {num_rounds} rounds\")\n",
    "        print(f\"Group members: {self.state.group_users}\")\n",
    "        print(f\"Method: {method.upper()}, Reward: R_{reward_function}\")\n",
    "        print(\"-\" * 60)\n",
    "\n",
    "        all_recommendations = []\n",
    "        round_rewards = []\n",
    "\n",
    "        for round_num in range(1, num_rounds + 1):\n",
    "            print(f\"Round {round_num}:\")\n",
    "            \n",
    "            recommendations, satisfactions = self.recommend_round(k, method)\n",
    "            all_recommendations.append(recommendations)\n",
    "            \n",
    "            # Calculate reward based on specified function\n",
    "            if reward_function == 'rs':\n",
    "                reward = self.calculate_reward_rs()\n",
    "            else:\n",
    "                reward = self.calculate_reward_rsd()\n",
    "            \n",
    "            round_rewards.append(reward)\n",
    "            \n",
    "            print(f\"  Recommendations: {recommendations}\")\n",
    "            # Format output for better readability\n",
    "            formatted_satisfactions = {user: f\"{sat:.4f}\" for user, sat in satisfactions.items()}\n",
    "            print(f\"  User satisfactions: {formatted_satisfactions}\")\n",
    "            print(f\"  Round reward (R_{reward_function}): {reward:.4f}\")\n",
    "            \n",
    "            if round_num < num_rounds:\n",
    "                next_alpha = self.state.get_satisfaction_disparity()\n",
    "                print(f\"  Next round satisfaction disparity: {next_alpha:.4f}\")\n",
    "            print()\n",
    "        \n",
    "        # Final statistics\n",
    "        final_satO = self.state.calculate_overall_satisfaction()\n",
    "        final_groupSatO = self.state.calculate_group_satisfaction()\n",
    "        final_groupDisO = self.state.calculate_group_disagreement()\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(\"FINAL RESULTS:\")\n",
    "        # Format final output\n",
    "        formatted_final_satO = {user: f\"{sat:.4f}\" for user, sat in final_satO.items()}\n",
    "        print(f\"Overall user satisfactions (satO): {formatted_final_satO}\")\n",
    "        print(f\"Final group satisfaction (groupSatO): {final_groupSatO:.4f}\")\n",
    "        print(f\"Final group disagreement (groupDisO): {final_groupDisO:.4f}\")\n",
    "        print(f\"Average reward across rounds: {np.mean(round_rewards):.4f}\")\n",
    "        \n",
    "        return all_recommendations, round_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "feb7f437-b623-4cd2-8141-2f649f547cf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Testing Complete SQUIRREL Framework ===\n",
      "Selected 882 popular movies (min_ratings=30)\n",
      "\n",
      "======================================================================\n",
      "EXECUTING SEQUENTIAL GROUP RECOMMENDATIONS WITH SDAA\n",
      "======================================================================\n",
      "Starting sequential group recommendation for 3 rounds\n",
      "Group members: [1, 414, 599]\n",
      "Method: SDAA, Reward: R_rsd\n",
      "------------------------------------------------------------\n",
      "Round 1:\n",
      "    SDAA alpha parameter: 0.2765\n",
      "  Recommendations: [293, 318, 353, 16, 364]\n",
      "  User satisfactions: {1: '0.9893', 414: '0.7399', 599: '0.5677'}\n",
      "  Round reward (R_rsd): 0.6590\n",
      "  Next round satisfaction disparity: 0.4216\n",
      "\n",
      "Round 2:\n",
      "    SDAA alpha parameter: 0.4216\n",
      "  Recommendations: [180, 454, 17, 497, 508]\n",
      "  User satisfactions: {1: '0.9292', 414: '0.6647', 599: '0.4876'}\n",
      "  Round reward (R_rsd): 0.6391\n",
      "  Next round satisfaction disparity: 0.4415\n",
      "\n",
      "Round 3:\n",
      "    SDAA alpha parameter: 0.4415\n",
      "  Recommendations: [541, 529, 337, 252, 524]\n",
      "  User satisfactions: {1: '0.9216', 414: '0.7228', 599: '0.5337'}\n",
      "  Round reward (R_rsd): 0.6477\n",
      "\n",
      "============================================================\n",
      "FINAL RESULTS:\n",
      "Overall user satisfactions (satO): {1: '0.9467', 414: '0.7091', 599: '0.5297'}\n",
      "Final group satisfaction (groupSatO): 0.7285\n",
      "Final group disagreement (groupDisO): 0.4170\n",
      "Average reward across rounds: 0.6486\n",
      "=== SDAA Recommendation Test Complete ===\n",
      "Total rounds executed: 3\n",
      "Final average reward: 0.6486\n"
     ]
    }
   ],
   "source": [
    "# Test the complete SQUIRREL framework\n",
    "print(\"=== Testing Complete SQUIRREL Framework ===\")\n",
    "\n",
    "# Define test group\n",
    "test_group = [1, 414, 599]\n",
    "\n",
    "# Initialize the recommender system\n",
    "recommender = SQUIRRELRecommender(\n",
    "    group_users=test_group,\n",
    "    ratings_df=ratings_df,\n",
    "    user_ratings_dict=user_ratings_dict\n",
    ")\n",
    "\n",
    "# Run sequential recommendations with SDAA method\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EXECUTING SEQUENTIAL GROUP RECOMMENDATIONS WITH SDAA\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "recommendations, rewards = recommender.run_sequential_recommendation(\n",
    "    num_rounds=3, \n",
    "    k=5,\n",
    "    method='sdaa',\n",
    "    reward_function='rsd'\n",
    ")\n",
    "\n",
    "print(\"=== SDAA Recommendation Test Complete ===\")\n",
    "print(f\"Total rounds executed: {len(recommendations)}\")\n",
    "print(f\"Final average reward: {np.mean(rewards):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f7068a-2a14-4586-8a42-f4d9e84ae039",
   "metadata": {},
   "source": [
    "# Step 4: Presentation (5 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a54d91d3-ed6f-4b2d-b642-a64099e51536",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CONCLUSION: SDAA Sequential Recommendation Successfully Implemented\n",
      "======================================================================\n",
      "✓ Dynamic alpha adaptation demonstrated: 0.2765 → 0.4216 → 0.4415\n",
      "✓ Balanced performance achieved: Group Satisfaction = 0.7285, Disagreement = 0.4170\n",
      "✓ SDAA effectively protected minority interests while maintaining group satisfaction\n",
      "✓ Framework ready for extended testing with different groups and parameters\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CONCLUSION: SDAA Sequential Recommendation Successfully Implemented\")\n",
    "print(\"=\"*70)\n",
    "print(\"✓ Dynamic alpha adaptation demonstrated: 0.2765 → 0.4216 → 0.4415\")\n",
    "print(\"✓ Balanced performance achieved: Group Satisfaction = 0.7285, Disagreement = 0.4170\")\n",
    "print(\"✓ SDAA effectively protected minority interests while maintaining group satisfaction\")\n",
    "print(\"✓ Framework ready for extended testing with different groups and parameters\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6a10c4-537f-4ac1-b706-70af893927c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
