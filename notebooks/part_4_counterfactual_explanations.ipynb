{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5214aa3-4c4d-4635-a31b-981891d9c993",
   "metadata": {},
   "source": [
    "# Part IV: Counterfactual Explanations for Group Recommendations (25 points)\n",
    "**Students:** Oskari Perikangas, Xiaosi Huang  \n",
    "**Date:** November 28, 2025\n",
    "\n",
    "---\n",
    "\n",
    "# Step 1: Design - Counterfactual Explanation Method (10 points)\n",
    "\n",
    "Generate explanations of the form: **\"If the group had not watched items A, then item B would not be recommended\"**, where A is a minimal set of items that ensures fairness across all group members.\n",
    "\n",
    "We implement a **Grow & Prune algorithm** with **Pareto filtering** to generate group counterfactual explanations. The method is model-agnostic and uses only the group's interaction data.\n",
    "\n",
    "### Core Design Components\n",
    "\n",
    "#### 1. Item-Level Metrics (Slides p.12-14)\n",
    "\n",
    "**Recognition:** Measures how many group members rated an item\n",
    "$$rs(i,G) = \\frac{|\\{u \\in G : i \\in I_u\\}|}{|G|}$$\n",
    "Items known by the majority create more understandable and fairer explanations.\n",
    "\n",
    "**Average Rating:** Group's average rating for an item\n",
    "$$rate(i,G) = \\frac{\\sum_{u \\in G: i \\in I_u} r_{u,i}}{|\\{u \\in G : i \\in I_u\\}|}$$\n",
    "where $r_{u,i}$ is the rating user $u$ gave to item $i$. High-rated items have stronger influence on recommendations.\n",
    "\n",
    "**Influence:** Impact on target recommendation\n",
    "$$infl(i,t,G') = \\frac{\\sum_{u \\in G'} \\hat{r}_{u,t}}{|G'|}$$\n",
    "where $G' = \\{u \\in G : i \\in I_u\\}$ and $\\hat{r}_{u,t}$ is the predicted rating for target $t$. Ensures explanation items actually contribute to recommending the target.\n",
    "\n",
    "**Explanatory Power (fast estimation):** \n",
    "$$expwr(i,t,G) = sim(i,t) \\cdot \\frac{rate(i,G)}{5} \\cdot rs(i,G)$$\n",
    "where $sim(i,t)$ is item-item similarity from KNN model. Estimates influence without rebuilding recommender (reduces computation). Full validation performed during GROW and PRUNE phases.\n",
    "\n",
    "#### 2. Fairness Constraint (Slides p.16)\n",
    "\n",
    "To prevent single-user blame, we require at least 2/3 of group members to contribute:\n",
    "$$fair(G,E) = \\frac{|\\{u \\in G : \\exists i \\in E, i \\in I_u\\}|}{|G|} \\geq 0.67$$\n",
    "For a 3-person group, this means ≥2 members must have rated items in the explanation. Ensures collective responsibility.\n",
    "\n",
    "#### 3. Pareto Filtering (Slides p.18-19)\n",
    "\n",
    "Reduces candidates from ~1000+ to ~5 items:\n",
    "1. Pre-filter: Keep items with $rs(i,G) \\geq 0.5$ and $rate(i,G) \\geq 3.5$\n",
    "2. Limit to top-50 by rating\n",
    "3. Apply Skyline operator on {recognition, rating, influence, exp_power}\n",
    "4. Keep only non-dominated items\n",
    "\n",
    "Balances multiple objectives efficiently, reducing complexity from $O(n^2)$ to $O(k)$ where $k \\ll n$.\n",
    "\n",
    "#### 4. Grow & Prune Algorithm (Slides p.22)\n",
    "\n",
    "**GROW Phase:**\n",
    "- Iteratively add items from Pareto set\n",
    "- Rebuild recommender after each addition\n",
    "- Check if target disappears from top-N\n",
    "- Stop when valid counterfactual found\n",
    "\n",
    "**PRUNE Phase:**\n",
    "- Try removing each item\n",
    "- Keep only if removal breaks validity OR fairness < 0.67\n",
    "- Ensures minimality while preserving fairness\n",
    "\n",
    "Finds minimal explanation while maintaining the fairness constraint.\n",
    "\n",
    "### Implementation Flow\n",
    "```\n",
    "Input: Group G, Target t, Top-N list L\n",
    "\n",
    "1. Get candidates: C = {items rated ≥3.5 by any member} \\ {t}\n",
    "\n",
    "2. Pareto filtering:\n",
    "   - Pre-filter: rs ≥ 0.5, rate ≥ 3.5\n",
    "   - Limit to top-50 by rating\n",
    "   - Compute 4 metrics for each\n",
    "   - Keep non-dominated → P (~5 items)\n",
    "\n",
    "3. GROW:\n",
    "   E = []\n",
    "   for item in P:\n",
    "       E.add(item)\n",
    "       if target not in new_recommendations(G \\ E):\n",
    "           break\n",
    "\n",
    "4. PRUNE:\n",
    "   for item in E:\n",
    "       if valid without item AND fair(E \\ {item}) ≥ 0.67:\n",
    "           E.remove(item)\n",
    "\n",
    "5. Return E\n",
    "```\n",
    "\n",
    "### Group-Specific Adaptations\n",
    "\n",
    "- **Fairness threshold (0.67):** Ensures ≥67% member participation for 3-person groups\n",
    "- **Recognition prioritization:** Favors items known by majority\n",
    "- **Collective removal:** Tests removing items from all members simultaneously\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023d375f-0c04-42fb-94c9-ac0a18f20390",
   "metadata": {},
   "source": [
    "# Step 2: Implementation  (10 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02d6ff9d-4faf-4286-89f0-9c8f40c829ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "PART IV: Counterfactual Explanations for Group Recommendations\n",
      "============================================================\n",
      "\n",
      "Dataset loaded:\n",
      "  Ratings: 100836 rows\n",
      "  Users: 610\n",
      "  Movies: 9724\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 1: Import libraries and load data\n",
    "# ============================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from surprise import Dataset, Reader, KNNBasic\n",
    "from surprise.model_selection import cross_validate\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"PART IV: Counterfactual Explanations for Group Recommendations\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Load MovieLens 100K dataset\n",
    "ratings = pd.read_csv('../data/ml-latest-small/ratings.csv')\n",
    "movies = pd.read_csv('../data/ml-latest-small/movies.csv')\n",
    "\n",
    "print(f\"\\nDataset loaded:\")\n",
    "print(f\"  Ratings: {ratings.shape[0]} rows\")\n",
    "print(f\"  Users: {ratings['userId'].nunique()}\")\n",
    "print(f\"  Movies: {ratings['movieId'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e692efb-e137-41c0-b4d4-8db2f5a7a47f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Selecting Test Group\n",
      "============================================================\n",
      "\n",
      "Selected group: [105, 305, 477]\n",
      "Common movies (rated >= 3.5 by all): 81\n",
      "Common movies (rated >= 4.0 by all): 49\n",
      "\n",
      "User rating statistics:\n",
      "  User 105: mean=4.12, total=722, high-rated(>=3.5)=674\n",
      "  User 305: mean=3.92, total=677, high-rated(>=3.5)=507\n",
      "  User 477: mean=3.74, total=600, high-rated(>=3.5)=480\n",
      "\n",
      "Candidate space (min_rating=3.5): ~1275 items\n",
      "Candidate space (min_rating=4.0): ~1082 items\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 2: Select optimal test group for counterfactual explanation\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Selecting Test Group\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Based on overlap analysis and computational efficiency,\n",
    "# we select users with moderate activity and high rating overlap\n",
    "test_users = [105, 305, 477]\n",
    "\n",
    "# Verify selected group characteristics\n",
    "common = set(ratings[(ratings['userId'] == test_users[0]) & (ratings['rating'] >= 3.5)]['movieId'])\n",
    "for uid in test_users[1:]:\n",
    "    common &= set(ratings[(ratings['userId'] == uid) & (ratings['rating'] >= 3.5)]['movieId'])\n",
    "\n",
    "# Check common high-rated movies (>=4.0)\n",
    "common_4 = set(ratings[(ratings['userId'] == test_users[0]) & (ratings['rating'] >= 4.0)]['movieId'])\n",
    "for uid in test_users[1:]:\n",
    "    common_4 &= set(ratings[(ratings['userId'] == uid) & (ratings['rating'] >= 4.0)]['movieId'])\n",
    "\n",
    "print(f\"\\nSelected group: {test_users}\")\n",
    "print(f\"Common movies (rated >= 3.5 by all): {len(common)}\")\n",
    "print(f\"Common movies (rated >= 4.0 by all): {len(common_4)}\")\n",
    "\n",
    "# User statistics\n",
    "print(\"\\nUser rating statistics:\")\n",
    "for uid in test_users:\n",
    "    user_ratings = ratings[ratings['userId'] == uid]['rating']\n",
    "    high_rated = sum(user_ratings >= 3.5)\n",
    "    print(f\"  User {uid}: mean={user_ratings.mean():.2f}, \"\n",
    "          f\"total={len(user_ratings)}, \"\n",
    "          f\"high-rated(>=3.5)={high_rated}\")\n",
    "\n",
    "# Calculate candidate space for different thresholds\n",
    "total_candidates_35 = set()\n",
    "total_candidates_40 = set()\n",
    "for uid in test_users:\n",
    "    total_candidates_35.update(\n",
    "        set(ratings[(ratings['userId'] == uid) & (ratings['rating'] >= 3.5)]['movieId'])\n",
    "    )\n",
    "    total_candidates_40.update(\n",
    "        set(ratings[(ratings['userId'] == uid) & (ratings['rating'] >= 4.0)]['movieId'])\n",
    "    )\n",
    "\n",
    "print(f\"\\nCandidate space (min_rating=3.5): ~{len(total_candidates_35)} items\")\n",
    "print(f\"Candidate space (min_rating=4.0): ~{len(total_candidates_40)} items\")\n",
    "\n",
    "test_group = test_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d1b6cc2-3dee-4b77-87f6-efabe2c67b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Building Item-based KNN Recommender\n",
      "============================================================\n",
      "\n",
      "Evaluating k values:\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  k=10: RMSE=1.0106\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  k=20: RMSE=0.9871\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  k=30: RMSE=0.9785\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  k=40: RMSE=0.9742\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  k=50: RMSE=0.9695\n",
      "\n",
      "Optimal k = 50 (RMSE=0.9695)\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "Test group: [105, 305, 477]\n",
      "\n",
      "Top-10 group recommendations:\n",
      " 1. Postman, The (Postino, Il) (1994)                  4.09\n",
      "    [U105:4.17, U305:4.11, U477:4.00]\n",
      " 2. L.A. Story (1991)                                  4.08\n",
      "    [U105:4.14, U305:4.16, U477:3.93]\n",
      " 3. Strangers on a Train (1951)                        4.03\n",
      "    [U105:3.96, U305:4.27, U477:3.86]\n",
      " 4. Hoop Dreams (1994)                                 4.02\n",
      "    [U105:4.05, U305:4.17, U477:3.84]\n",
      " 5. Return of the Pink Panther, The (1975)             4.01\n",
      "    [U105:4.00, U305:4.30, U477:3.71]\n",
      " 6. Bowfinger (1999)                                   4.01\n",
      "    [U105:3.96, U305:4.20, U477:3.86]\n",
      " 7. Being There (1979)                                 4.00\n",
      "    [U105:4.03, U305:4.15, U477:3.81]\n",
      " 8. Elf (2003)                                         3.99\n",
      "    [U105:4.27, U305:3.96, U477:3.74]\n",
      " 9. Gods Must Be Crazy, The (1980)                     3.98\n",
      "    [U105:4.03, U305:4.10, U477:3.82]\n",
      "10. Like Water for Chocolate (Como agua para chocolate) (1992) 3.98\n",
      "    [U105:4.03, U305:4.09, U477:3.82]\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 3: Item-based KNN Group Recommender\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Building Item-based KNN Recommender\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Cross-validation to find optimal k\n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "\n",
    "k_values = [10, 20, 30, 40, 50]\n",
    "cv_results = {}\n",
    "\n",
    "print(\"\\nEvaluating k values:\")\n",
    "for k in k_values:\n",
    "    # Item-based similarity for group recommendations\n",
    "    sim_options = {'name': 'pearson', 'user_based': False}\n",
    "    algo = KNNBasic(k=k, sim_options=sim_options)\n",
    "    cv_out = cross_validate(algo, data, measures=['RMSE'], cv=3, verbose=False)\n",
    "    cv_results[k] = cv_out['test_rmse'].mean()\n",
    "    print(f\"  k={k}: RMSE={cv_results[k]:.4f}\")\n",
    "\n",
    "optimal_k = min(cv_results, key=cv_results.get)\n",
    "print(f\"\\nOptimal k = {optimal_k} (RMSE={cv_results[optimal_k]:.4f})\")\n",
    "\n",
    "\n",
    "class MovieRecommender:\n",
    "    \"\"\"\n",
    "    Item-based KNN recommender with average aggregation.\n",
    "    \n",
    "    Item-based CF is more suitable for group recommendations than user-based CF\n",
    "    because it provides more stable predictions across diverse group preferences.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, ratings_df, k, sim_name='pearson', min_ratings=20):\n",
    "        self.ratings_df = ratings_df\n",
    "        self.k = k\n",
    "        self.sim_name = sim_name\n",
    "        self.min_ratings = min_ratings\n",
    "        \n",
    "        # Build Surprise trainset\n",
    "        reader = Reader(rating_scale=(0.5, 5.0))\n",
    "        dataset = Dataset.load_from_df(\n",
    "            ratings_df[['userId', 'movieId', 'rating']], reader\n",
    "        )\n",
    "        self.trainset = dataset.build_full_trainset()\n",
    "        \n",
    "        # Train item-based KNN model\n",
    "        sim_options = {'name': sim_name, 'user_based': False}\n",
    "        self.model = KNNBasic(k=k, sim_options=sim_options)\n",
    "        self.model.fit(self.trainset)\n",
    "        \n",
    "        # Cache movie mean ratings for fallback\n",
    "        self.movie_mean = ratings_df.groupby(\"movieId\")[\"rating\"].mean()\n",
    "    \n",
    "    def predict_for_user(self, user_id, movie_id):\n",
    "        \"\"\"\n",
    "        Predict rating with multi-level fallback mechanism.\n",
    "        \n",
    "        Returns:\n",
    "            Predicted rating (float)\n",
    "        \"\"\"\n",
    "        try:\n",
    "            est = self.model.predict(user_id, movie_id).est\n",
    "            if est is None or np.isnan(est):\n",
    "                raise ValueError\n",
    "            return est\n",
    "        except:\n",
    "            # Fallback: use movie mean or global mean\n",
    "            return self.movie_mean.get(movie_id, 3.0)\n",
    "    \n",
    "    def get_group_recommendations(self, user_ids, n=10, min_ratings=None):\n",
    "        \"\"\"\n",
    "        Generate group recommendations using average aggregation.\n",
    "        \n",
    "        Only recommends movies that no group member has rated (unseen movies).\n",
    "        \n",
    "        Args:\n",
    "            user_ids: List of user IDs in the group\n",
    "            n: Number of recommendations to return\n",
    "            min_ratings: Minimum number of ratings required for a movie\n",
    "        \n",
    "        Returns:\n",
    "            List of (movie_id, group_score) tuples, sorted by score\n",
    "        \"\"\"\n",
    "        if min_ratings is None:\n",
    "            min_ratings = self.min_ratings\n",
    "        \n",
    "        # Find movies already rated by any group member\n",
    "        seen_movies = set()\n",
    "        for uid in user_ids:\n",
    "            seen_movies.update(\n",
    "                self.ratings_df[self.ratings_df.userId == uid].movieId\n",
    "            )\n",
    "        \n",
    "        # Filter popular movies (with sufficient ratings)\n",
    "        movie_counts = self.ratings_df.groupby(\"movieId\").size()\n",
    "        popular_movies = movie_counts[movie_counts >= min_ratings].index.tolist()\n",
    "        \n",
    "        # Candidates = popular AND unseen\n",
    "        candidates = [m for m in popular_movies if m not in seen_movies]\n",
    "        \n",
    "        # Compute group score = average of individual predictions\n",
    "        group_scores = {\n",
    "            m: np.mean([self.predict_for_user(uid, m) for uid in user_ids])\n",
    "            for m in candidates\n",
    "        }\n",
    "        \n",
    "        # Return top-N ranked by group score\n",
    "        return sorted(group_scores.items(), key=lambda x: x[1], reverse=True)[:n]\n",
    "\n",
    "\n",
    "# Build recommender\n",
    "recommender = MovieRecommender(ratings, k=optimal_k, min_ratings=20)\n",
    "\n",
    "# Generate group recommendations\n",
    "print(f\"\\nTest group: {test_group}\")\n",
    "recommendations = recommender.get_group_recommendations(test_group, n=10)\n",
    "\n",
    "print(\"\\nTop-10 group recommendations:\")\n",
    "for rank, (movie_id, score) in enumerate(recommendations, 1):\n",
    "    title = movies[movies.movieId == movie_id][\"title\"].values[0]\n",
    "    preds = [f\"U{uid}:{recommender.predict_for_user(uid, movie_id):.2f}\" \n",
    "             for uid in test_group]\n",
    "    print(f\"{rank:2d}. {title:<50s} {score:.2f}\")\n",
    "    print(f\"    [{', '.join(preds)}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6895356b-379b-4d65-b73d-7c1e9cdfdcd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Defining Counterfactual Explainer\n",
      "============================================================\n",
      "Explainer class defined\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 4: Group Counterfactual Explainer (Grow & Prune & Pareto filtering)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Defining Counterfactual Explainer\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "\n",
    "class GroupCounterfactualExplainer:\n",
    "    \"\"\"\n",
    "    Grow & Prune algorithm for group counterfactual explanations.\n",
    "    \n",
    "    Based on slides: \"Explaining Group Recommendations via Counterfactuals\"\n",
    "    Implements model-agnostic explanation using group interaction history.\n",
    "    \n",
    "    Key features:\n",
    "    - Item-level metrics: recognition, rating, influence, explanatory_power\n",
    "    - Utility metrics: fairness, minimality\n",
    "    - Pareto filtering for candidate reduction\n",
    "    - Grow & Prune algorithm for minimal explanation\n",
    "    \n",
    "    Slides references:\n",
    "    - Item metrics: pages 12-14\n",
    "    - Fairness: page 16\n",
    "    - Pareto filtering: pages 18-19\n",
    "    - Grow & Prune: page 22\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, ratings_df, movies_df, base_recommender):\n",
    "        self.ratings_df = ratings_df\n",
    "        self.movies_df = movies_df\n",
    "        self.base_recommender = base_recommender\n",
    "        self.k = base_recommender.k\n",
    "        self.sim_name = base_recommender.sim_name\n",
    "        self.min_ratings = base_recommender.min_ratings\n",
    "    \n",
    "    def _build_recommender(self, ratings_df):\n",
    "        \"\"\"Rebuild recommender on modified ratings (for counterfactual testing).\"\"\"\n",
    "        return MovieRecommender(\n",
    "            ratings_df, \n",
    "            k=self.k, \n",
    "            sim_name=self.sim_name,\n",
    "            min_ratings=self.min_ratings\n",
    "        )\n",
    "    \n",
    "    def _group_list(self, recommender, group_ids, top_n):\n",
    "        \"\"\"Get group recommendation list.\"\"\"\n",
    "        return recommender.get_group_recommendations(\n",
    "            user_ids=group_ids,\n",
    "            n=top_n,\n",
    "            min_ratings=self.min_ratings\n",
    "        )\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Helper: user/group interactions\n",
    "    # ========================================================================\n",
    "    \n",
    "    def get_user_items(self, user_id):\n",
    "        \"\"\"Get all items rated by user.\"\"\"\n",
    "        return set(\n",
    "            self.ratings_df.loc[\n",
    "                self.ratings_df[\"userId\"] == user_id, \"movieId\"\n",
    "            ].values\n",
    "        )\n",
    "    \n",
    "    def get_group_items(self, group_ids, min_rating=None):\n",
    "        \"\"\"\n",
    "        Get all items rated by any group member.\n",
    "        \n",
    "        Args:\n",
    "            min_rating: Optional threshold (e.g., 3.5 for 'liked' items)\n",
    "        \"\"\"\n",
    "        mask = self.ratings_df[\"userId\"].isin(group_ids)\n",
    "        df = self.ratings_df.loc[mask]\n",
    "        \n",
    "        if min_rating is not None:\n",
    "            df = df[df[\"rating\"] >= min_rating]\n",
    "        \n",
    "        return set(df[\"movieId\"].values)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Item-level metrics (Slides pages 12-14)\n",
    "    # ========================================================================\n",
    "    \n",
    "    def recognition(self, item_id, group_ids):\n",
    "        \"\"\"\n",
    "        Recognition: rs(i,S) = (# users who rated i) / |S|\n",
    "        Slides page 12\n",
    "        \"\"\"\n",
    "        count = sum(1 for u in group_ids if item_id in self.get_user_items(u))\n",
    "        return count / len(group_ids)\n",
    "    \n",
    "    def rating(self, item_id, group_ids):\n",
    "        \"\"\"\n",
    "        Average rating: rate(i,S) = avg(ratings given to i by group)\n",
    "        Slides page 12\n",
    "        \"\"\"\n",
    "        ratings_list = []\n",
    "        for u in group_ids:\n",
    "            r = self.ratings_df[\n",
    "                (self.ratings_df[\"userId\"] == u) &\n",
    "                (self.ratings_df[\"movieId\"] == item_id)\n",
    "            ][\"rating\"]\n",
    "            if len(r) > 0:\n",
    "                ratings_list.append(float(r.values[0]))\n",
    "        \n",
    "        return np.mean(ratings_list) if ratings_list else 0.0\n",
    "    \n",
    "    def influence(self, item_id, target_id, group_ids):\n",
    "        \"\"\"\n",
    "        Influence: infl(i,t,G') = avg recScore(t) for users in G'\n",
    "        where G' = {users in group who rated item i}\n",
    "        Slides page 14\n",
    "        \"\"\"\n",
    "        G_prime = [u for u in group_ids if item_id in self.get_user_items(u)]\n",
    "        if not G_prime:\n",
    "            return 0.0\n",
    "        \n",
    "        scores = [\n",
    "            self.base_recommender.predict_for_user(u, target_id)\n",
    "            for u in G_prime\n",
    "        ]\n",
    "        return float(np.mean(scores))\n",
    "    \n",
    "    def explanatory_power_fast(self, removed_items, target_id, group_ids):\n",
    "        \"\"\"\n",
    "        Fast explanatory power estimation using item-item similarity.\n",
    "        \n",
    "        Estimates influence without rebuilding recommender:\n",
    "        - Uses similarity from KNN model\n",
    "        - Weights by group's rating and recognition\n",
    "        \n",
    "        Returns: Score in [0, 1]\n",
    "        \"\"\"\n",
    "        if not removed_items:\n",
    "            return 0.0\n",
    "        \n",
    "        influences = []\n",
    "        for item in removed_items:\n",
    "            try:\n",
    "                # Get item-item similarity from KNN model\n",
    "                inner_item = self.base_recommender.trainset.to_inner_iid(item)\n",
    "                inner_target = self.base_recommender.trainset.to_inner_iid(target_id)\n",
    "                sim = self.base_recommender.model.sim[inner_item, inner_target]\n",
    "                \n",
    "                # Weight by group's preference strength\n",
    "                item_rating = self.rating(item, group_ids)\n",
    "                item_recognition = self.recognition(item, group_ids)\n",
    "                \n",
    "                # Combined influence score\n",
    "                influence = sim * (item_rating / 5.0) * item_recognition\n",
    "                influences.append(influence)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if not influences:\n",
    "            return 0.0\n",
    "        \n",
    "        return float(np.mean(influences))\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Fairness (Slides page 16)\n",
    "    # ========================================================================\n",
    "    \n",
    "    def fairness(self, explanation_items, group_ids):\n",
    "        \"\"\"\n",
    "        Fairness: fair(G,E) = (# users who rated >= 1 item in E) / |G|\n",
    "        \n",
    "        Ensures explanation doesn't single out one user.\n",
    "        \"\"\"\n",
    "        covered = sum(\n",
    "            1 for u in group_ids\n",
    "            if any(i in self.get_user_items(u) for i in explanation_items)\n",
    "        )\n",
    "        return covered / len(group_ids)\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Counterfactual validity check\n",
    "    # ========================================================================\n",
    "    \n",
    "    def is_counterfactual(self, explanation_items, target_id, group_ids, top_n):\n",
    "        \"\"\"\n",
    "        Check if explanation is valid counterfactual.\n",
    "        \n",
    "        Valid = target no longer appears in top-N after removing explanation items.\n",
    "        \n",
    "        Returns:\n",
    "            (is_valid, new_rank or None)\n",
    "        \"\"\"\n",
    "        # Remove items from ratings\n",
    "        mask_remove = (\n",
    "            self.ratings_df[\"movieId\"].isin(explanation_items) &\n",
    "            self.ratings_df[\"userId\"].isin(group_ids)\n",
    "        )\n",
    "        temp_ratings = self.ratings_df.loc[~mask_remove].copy()\n",
    "        # Rebuild recommender\n",
    "        temp_rec = self._build_recommender(temp_ratings)\n",
    "        # Check if target disappears\n",
    "        new_list = self._group_list(temp_rec, group_ids, top_n)\n",
    "        new_items = [mid for (mid, _) in new_list]\n",
    "        \n",
    "        if target_id not in new_items:\n",
    "            return True, None\n",
    "        else:\n",
    "            return False, new_items.index(target_id) + 1\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Pareto filtering (Slides pages 18-19)\n",
    "    # ========================================================================\n",
    "    \n",
    "    def pareto_filter(self, candidates, group_ids, target_id, top_k=50):\n",
    "        \"\"\"\n",
    "        Apply Pareto filtering to reduce candidate space.\n",
    "        \n",
    "        Strategy:\n",
    "        1. Pre-filter: Keep high-quality items (recognition >= 0.5, rating >= 3.5)\n",
    "        2. Limit: Take top-K by rating if still too many\n",
    "        3. Compute metrics: Calculate all 4 metrics for remaining items\n",
    "        4. Pareto: Keep only non-dominated items\n",
    "        \n",
    "        Args:\n",
    "            top_k: Maximum candidates to consider before Pareto filtering\n",
    "        \n",
    "        Returns:\n",
    "            (ordered_items, metrics_dict)\n",
    "        \"\"\"\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Pareto Filtering\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        candidates = list(set(candidates))\n",
    "        print(f\"Initial candidates: {len(candidates)}\")\n",
    "        \n",
    "        # Step 1: Pre-filtering with basic metrics\n",
    "        print(\"\\nStep 1: Pre-filtering...\")\n",
    "        metrics = {}\n",
    "        for i in tqdm(candidates, desc=\"Computing basic metrics\"):\n",
    "            metrics[i] = {\n",
    "                \"rec\": self.recognition(i, group_ids),\n",
    "                \"rate\": self.rating(i, group_ids),\n",
    "            }\n",
    "        \n",
    "        # Keep items with recognition >= 0.5 and rating >= 3.5\n",
    "        filtered = [\n",
    "            i for i in candidates \n",
    "            if metrics[i][\"rec\"] >= 0.5 and metrics[i][\"rate\"] >= 3.5\n",
    "        ]\n",
    "        print(f\"After pre-filtering: {len(filtered)} items\")\n",
    "        \n",
    "        # Step 2: Limit to top-K by rating\n",
    "        if len(filtered) > top_k:\n",
    "            filtered = sorted(\n",
    "                filtered, \n",
    "                key=lambda i: metrics[i][\"rate\"], \n",
    "                reverse=True\n",
    "            )[:top_k]\n",
    "            print(f\"Limited to top-{top_k}: {len(filtered)} items\")\n",
    "        \n",
    "        # Step 3: Compute expensive metrics\n",
    "        print(\"\\nStep 2: Computing influence & explanatory power...\")\n",
    "        for i in tqdm(filtered, desc=\"Computing metrics\"):\n",
    "            metrics[i][\"infl\"] = self.influence(i, target_id, group_ids)\n",
    "            metrics[i][\"exp\"] = self.explanatory_power_fast([i], target_id, group_ids)\n",
    "        \n",
    "        # Step 4: Pareto filtering\n",
    "        print(\"\\nStep 3: Pareto filtering...\")\n",
    "        pareto_items = []\n",
    "        for a in filtered:\n",
    "            dominated = False\n",
    "            for b in filtered:\n",
    "                if a == b:\n",
    "                    continue\n",
    "                ma, mb = metrics[a], metrics[b]\n",
    "                \n",
    "                # Check if b dominates a\n",
    "                if (mb[\"rec\"] >= ma[\"rec\"] and\n",
    "                    mb[\"rate\"] >= ma[\"rate\"] and\n",
    "                    mb[\"infl\"] >= ma[\"infl\"] and\n",
    "                    mb[\"exp\"] >= ma[\"exp\"] and\n",
    "                    (mb[\"rec\"] > ma[\"rec\"] or\n",
    "                     mb[\"rate\"] > ma[\"rate\"] or\n",
    "                     mb[\"infl\"] > ma[\"infl\"] or\n",
    "                     mb[\"exp\"] > ma[\"exp\"])):\n",
    "                    dominated = True\n",
    "                    break\n",
    "            \n",
    "            if not dominated:\n",
    "                pareto_items.append(a)\n",
    "        \n",
    "        print(f\"After Pareto: {len(pareto_items)} items\")\n",
    "        \n",
    "        # Sort by weighted score\n",
    "        ordered = sorted(\n",
    "            pareto_items,\n",
    "            key=lambda i: (\n",
    "                metrics[i][\"exp\"] * 0.4 +\n",
    "                metrics[i][\"infl\"] * 0.3 +\n",
    "                metrics[i][\"rate\"] * 0.2 +\n",
    "                metrics[i][\"rec\"] * 0.1\n",
    "            ),\n",
    "            reverse=True\n",
    "        )\n",
    "        \n",
    "        return ordered, metrics\n",
    "    \n",
    "    # ========================================================================\n",
    "    # Grow & Prune (Slides page 22)\n",
    "    # ========================================================================\n",
    "    \n",
    "    def grow_and_prune(self, group_ids, target_id, original_list,\n",
    "                       max_size=8, use_pareto=True, min_rating=3.5):\n",
    "        \"\"\"\n",
    "        Grow & Prune algorithm for minimal counterfactual explanation.\n",
    "        \n",
    "        Phase 1 (GROW): Add items until valid counterfactual found\n",
    "        Phase 2 (PRUNE): Remove redundant items while maintaining validity\n",
    "        \n",
    "        Args:\n",
    "            group_ids: User IDs in the group\n",
    "            target_id: Movie to explain\n",
    "            original_list: Original recommendation list\n",
    "            max_size: Maximum explanation size\n",
    "            use_pareto: Whether to apply Pareto filtering\n",
    "            min_rating: Minimum rating threshold for candidates\n",
    "        \n",
    "        Returns:\n",
    "            (explanation, metrics_dict)\n",
    "        \"\"\"\n",
    "        top_n = len(original_list)\n",
    "        \n",
    "        # Get candidates: movies rated >= min_rating by group\n",
    "        candidates = list(self.get_group_items(group_ids, min_rating=min_rating))\n",
    "        \n",
    "        if target_id in candidates:\n",
    "            candidates.remove(target_id)\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"Grow & Prune Algorithm\")\n",
    "        print(\"=\"*60)\n",
    "        print(f\"Candidate items: {len(candidates)}\")\n",
    "        \n",
    "        # Apply Pareto filtering or compute metrics\n",
    "        if use_pareto and candidates:\n",
    "            ordered_candidates, metrics = self.pareto_filter(\n",
    "                candidates, group_ids, target_id, top_k=50\n",
    "            )\n",
    "        else:\n",
    "            # Compute metrics without Pareto filtering\n",
    "            metrics = {}\n",
    "            for i in tqdm(candidates, desc=\"Computing metrics\"):\n",
    "                metrics[i] = {\n",
    "                    \"rec\": self.recognition(i, group_ids),\n",
    "                    \"rate\": self.rating(i, group_ids),\n",
    "                    \"infl\": self.influence(i, target_id, group_ids),\n",
    "                    \"exp\": self.explanatory_power_fast([i], target_id, group_ids),\n",
    "                }\n",
    "            ordered_candidates = sorted(\n",
    "                candidates,\n",
    "                key=lambda i: sum(metrics[i].values()),\n",
    "                reverse=True\n",
    "            )\n",
    "        \n",
    "        # ====================================================================\n",
    "        # Phase 1: GROW\n",
    "        # ====================================================================\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"GROW Phase\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        explanation = []\n",
    "        found = False\n",
    "        \n",
    "        for item in ordered_candidates:\n",
    "            if len(explanation) >= max_size:\n",
    "                break\n",
    "            \n",
    "            explanation.append(item)\n",
    "            valid, new_rank = self.is_counterfactual(\n",
    "                explanation, target_id, group_ids, top_n\n",
    "            )\n",
    "            \n",
    "            title = self.movies_df.loc[\n",
    "                self.movies_df[\"movieId\"] == item, \"title\"\n",
    "            ].values[0]\n",
    "            fair = self.fairness(explanation, group_ids)\n",
    "            \n",
    "            print(f\"\\n+ Added: {title[:45]}\")\n",
    "            print(f\"  Metrics: rec={metrics[item]['rec']:.2f}, \"\n",
    "                  f\"rate={metrics[item]['rate']:.2f}, \"\n",
    "                  f\"infl={metrics[item]['infl']:.2f}, \"\n",
    "                  f\"exp={metrics[item]['exp']:.3f}\")\n",
    "            print(f\"  Size: {len(explanation)}, Fairness: {fair:.2f}, Valid: {valid}\")\n",
    "            \n",
    "            if valid:\n",
    "                found = True\n",
    "                print(\"  ✓ Valid counterfactual found\")\n",
    "                break\n",
    "        \n",
    "        if not found:\n",
    "            print(\"\\n⚠ No valid counterfactual found\")\n",
    "            return explanation, {\n",
    "                \"valid\": False,\n",
    "                \"size\": len(explanation),\n",
    "                \"fairness\": self.fairness(explanation, group_ids) if explanation else 0.0,\n",
    "            }\n",
    "        \n",
    "        # ====================================================================\n",
    "        # Phase 2: PRUNE\n",
    "        # ====================================================================\n",
    "        print(\"\\n\" + \"=\"*60)\n",
    "        print(\"PRUNE Phase\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        for item in explanation.copy():\n",
    "            reduced = [x for x in explanation if x != item]\n",
    "            if not reduced:\n",
    "                continue\n",
    "            \n",
    "            # Check validity and fairness\n",
    "            valid, _ = self.is_counterfactual(reduced, target_id, group_ids, top_n)\n",
    "            fairness_reduced = self.fairness(reduced, group_ids)\n",
    "            \n",
    "            title = self.movies_df.loc[\n",
    "                self.movies_df[\"movieId\"] == item, \"title\"\n",
    "            ].values[0]\n",
    "            \n",
    "            # Keep item if removing hurts validity or fairness\n",
    "            if valid and fairness_reduced >= 0.67:\n",
    "                explanation.remove(item)\n",
    "                print(f\"  - Removed: {title[:45]} (redundant, fairness={fairness_reduced:.2f})\")\n",
    "            else:\n",
    "                if not valid:\n",
    "                    reason = \"validity\"\n",
    "                else:\n",
    "                    reason = f\"fairness (would drop to {fairness_reduced:.2f})\"\n",
    "                print(f\"  ✓ Kept: {title[:45]} (necessary for {reason})\")\n",
    "        \n",
    "        # Calculate final metrics\n",
    "        if explanation:\n",
    "            avg_metrics = {\n",
    "                \"avg_recognition\": np.mean([metrics[i][\"rec\"] for i in explanation]),\n",
    "                \"avg_rating\": np.mean([metrics[i][\"rate\"] for i in explanation]),\n",
    "                \"avg_influence\": np.mean([metrics[i][\"infl\"] for i in explanation]),\n",
    "                \"avg_exp_power\": np.mean([metrics[i][\"exp\"] for i in explanation]),\n",
    "            }\n",
    "        else:\n",
    "            avg_metrics = {\n",
    "                \"avg_recognition\": 0.0,\n",
    "                \"avg_rating\": 0.0,\n",
    "                \"avg_influence\": 0.0,\n",
    "                \"avg_exp_power\": 0.0,\n",
    "            }\n",
    "        \n",
    "        summary = {\n",
    "            \"valid\": True,\n",
    "            \"size\": len(explanation),\n",
    "            \"fairness\": self.fairness(explanation, group_ids),\n",
    "            **avg_metrics\n",
    "        }\n",
    "        \n",
    "        return explanation, summary\n",
    "\n",
    "\n",
    "print(\"Explainer class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6cca9e6a-748d-4698-86a7-3c0fae592379",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Generating Explanation\n",
      "============================================================\n",
      "\n",
      "Group: [105, 305, 477]\n",
      "Target: #7 - Being There (1979)\n",
      "\n",
      "============================================================\n",
      "Grow & Prune Algorithm\n",
      "============================================================\n",
      "Candidate items: 1275\n",
      "\n",
      "============================================================\n",
      "Pareto Filtering\n",
      "============================================================\n",
      "Initial candidates: 1275\n",
      "\n",
      "Step 1: Pre-filtering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing basic metrics: 100%|████████████| 1275/1275 [00:00<00:00, 1293.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pre-filtering: 345 items\n",
      "Limited to top-50: 50 items\n",
      "\n",
      "Step 2: Computing influence & explanatory power...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing metrics: 100%|███████████████████████| 50/50 [00:00<00:00, 709.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Pareto filtering...\n",
      "After Pareto: 3 items\n",
      "\n",
      "============================================================\n",
      "GROW Phase\n",
      "============================================================\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "+ Added: Departed, The (2006)\n",
      "  Metrics: rec=1.00, rate=4.83, infl=4.00, exp=0.967\n",
      "  Size: 1, Fairness: 1.00, Valid: True\n",
      "  ✓ Valid counterfactual found\n",
      "\n",
      "============================================================\n",
      "PRUNE Phase\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "COUNTERFACTUAL EXPLANATION\n",
      "============================================================\n",
      "\n",
      "If the group had NOT watched these 1 movies,\n",
      "then 'Being There (1979)' would NOT be recommended.\n",
      "\n",
      "Movies in explanation:\n",
      "------------------------------------------------------------\n",
      "1. Departed, The (2006)\n",
      "   U105:5.0★, U305:4.5★, U477:5.0★\n",
      "\n",
      "------------------------------------------------------------\n",
      "Explanation quality metrics:\n",
      "------------------------------------------------------------\n",
      "  Size:               1\n",
      "  Fairness:           1.00 (all members)\n",
      "  Avg recognition:    1.000\n",
      "  Avg rating:         4.833\n",
      "  Avg influence:      3.997\n",
      "  Avg exp power:      0.967\n",
      "\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5.1 : Generate Counterfactual Explanation (only single rank)\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Generating Explanation\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Select target movie to explain (can change rank from 1-10)\n",
    "target_rank = 7\n",
    "target_movie_id = recommendations[target_rank - 1][0]\n",
    "target_title = movies.loc[movies[\"movieId\"] == target_movie_id, \"title\"].values[0]\n",
    "\n",
    "print(f\"\\nGroup: {test_group}\")\n",
    "print(f\"Target: #{target_rank} - {target_title}\")\n",
    "\n",
    "# Original recommendation list\n",
    "original_list = recommendations\n",
    "\n",
    "# Build explainer\n",
    "explainer = GroupCounterfactualExplainer(\n",
    "    ratings_df=ratings,\n",
    "    movies_df=movies,\n",
    "    base_recommender=recommender\n",
    ")\n",
    "\n",
    "# Run Grow & Prune algorithm\n",
    "explanation, metrics = explainer.grow_and_prune(\n",
    "    group_ids=test_group,\n",
    "    target_id=target_movie_id,\n",
    "    original_list=original_list,\n",
    "    max_size=8,\n",
    "    use_pareto=True,\n",
    "    min_rating=3.5  # Can adjust: 3.5 or 4.0\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Display results\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COUNTERFACTUAL EXPLANATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if not metrics.get(\"valid\", False):\n",
    "    print(\"\\n⚠ No valid explanation found\")\n",
    "else:\n",
    "    # Natural language explanation\n",
    "    print(f\"\\nIf the group had NOT watched these {len(explanation)} movies,\")\n",
    "    print(f\"then '{target_title}' would NOT be recommended.\\n\")\n",
    "    \n",
    "    # List movies in explanation\n",
    "    print(\"Movies in explanation:\")\n",
    "    print(\"-\"*60)\n",
    "    for idx, item_id in enumerate(explanation, 1):\n",
    "        title = movies.loc[movies[\"movieId\"] == item_id, \"title\"].values[0]\n",
    "        print(f\"{idx}. {title}\")\n",
    "        \n",
    "        # Show which users rated it\n",
    "        raters = []\n",
    "        for u in test_group:\n",
    "            r = ratings[\n",
    "                (ratings[\"userId\"] == u) & (ratings[\"movieId\"] == item_id)\n",
    "            ][\"rating\"]\n",
    "            if len(r) > 0:\n",
    "                raters.append(f\"U{u}:{r.values[0]:.1f}★\")\n",
    "        \n",
    "        if raters:\n",
    "            print(f\"   {', '.join(raters)}\")\n",
    "    \n",
    "    # Quality metrics\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"Explanation quality metrics:\")\n",
    "    print(\"-\"*60)\n",
    "    print(f\"  Size:               {metrics['size']}\")\n",
    "    print(f\"  Fairness:           {metrics['fairness']:.2f} \"\n",
    "          f\"({'all members' if metrics['fairness'] == 1.0 else 'partial'})\")\n",
    "    print(f\"  Avg recognition:    {metrics['avg_recognition']:.3f}\")\n",
    "    print(f\"  Avg rating:         {metrics['avg_rating']:.3f}\")\n",
    "    print(f\"  Avg influence:      {metrics['avg_influence']:.3f}\")\n",
    "    print(f\"  Avg exp power:      {metrics['avg_exp_power']:.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4521e48-8128-45d5-bba5-a56227349735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Running Counterfactual Explanations for Rank 1–10\n",
      "============================================================\n",
      "\n",
      "============================================================\n",
      "TARGET RANK: 1\n",
      "============================================================\n",
      "Group: [105, 305, 477]\n",
      "Target #1: Postman, The (Postino, Il) (1994)\n",
      "\n",
      "============================================================\n",
      "Grow & Prune Algorithm\n",
      "============================================================\n",
      "Candidate items: 1275\n",
      "\n",
      "============================================================\n",
      "Pareto Filtering\n",
      "============================================================\n",
      "Initial candidates: 1275\n",
      "\n",
      "Step 1: Pre-filtering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing basic metrics: 100%|████████████| 1275/1275 [00:00<00:00, 1284.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pre-filtering: 345 items\n",
      "Limited to top-50: 50 items\n",
      "\n",
      "Step 2: Computing influence & explanatory power...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing metrics: 100%|███████████████████████| 50/50 [00:00<00:00, 681.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Pareto filtering...\n",
      "After Pareto: 3 items\n",
      "\n",
      "============================================================\n",
      "GROW Phase\n",
      "============================================================\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "+ Added: WALL·E (2008)\n",
      "  Metrics: rec=1.00, rate=5.00, infl=4.09, exp=0.952\n",
      "  Size: 1, Fairness: 1.00, Valid: False\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "+ Added: City of God (Cidade de Deus) (2002)\n",
      "  Metrics: rec=0.67, rate=5.00, infl=4.14, exp=0.589\n",
      "  Size: 2, Fairness: 1.00, Valid: False\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "+ Added: Old Boy (2003)\n",
      "  Metrics: rec=0.67, rate=4.75, infl=4.14, exp=0.633\n",
      "  Size: 3, Fairness: 1.00, Valid: False\n",
      "\n",
      "⚠ No valid counterfactual found\n",
      "\n",
      "---- Explanation ----\n",
      "⚠ No valid explanation found\n",
      "\n",
      "============================================================\n",
      "TARGET RANK: 2\n",
      "============================================================\n",
      "Group: [105, 305, 477]\n",
      "Target #2: L.A. Story (1991)\n",
      "\n",
      "============================================================\n",
      "Grow & Prune Algorithm\n",
      "============================================================\n",
      "Candidate items: 1275\n",
      "\n",
      "============================================================\n",
      "Pareto Filtering\n",
      "============================================================\n",
      "Initial candidates: 1275\n",
      "\n",
      "Step 1: Pre-filtering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing basic metrics: 100%|████████████| 1275/1275 [00:01<00:00, 1243.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pre-filtering: 345 items\n",
      "Limited to top-50: 50 items\n",
      "\n",
      "Step 2: Computing influence & explanatory power...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing metrics: 100%|███████████████████████| 50/50 [00:00<00:00, 667.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Pareto filtering...\n",
      "After Pareto: 4 items\n",
      "\n",
      "============================================================\n",
      "GROW Phase\n",
      "============================================================\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "+ Added: Donnie Darko (2001)\n",
      "  Metrics: rec=1.00, rate=5.00, infl=4.08, exp=0.683\n",
      "  Size: 1, Fairness: 1.00, Valid: False\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "+ Added: Full Metal Jacket (1987)\n",
      "  Metrics: rec=1.00, rate=4.67, infl=4.08, exp=0.707\n",
      "  Size: 2, Fairness: 1.00, Valid: False\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "+ Added: Clockwork Orange, A (1971)\n",
      "  Metrics: rec=0.67, rate=5.00, infl=4.15, exp=0.345\n",
      "  Size: 3, Fairness: 1.00, Valid: False\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "+ Added: Requiem for a Dream (2000)\n",
      "  Metrics: rec=0.67, rate=4.75, infl=4.15, exp=0.409\n",
      "  Size: 4, Fairness: 1.00, Valid: False\n",
      "\n",
      "⚠ No valid counterfactual found\n",
      "\n",
      "---- Explanation ----\n",
      "⚠ No valid explanation found\n",
      "\n",
      "============================================================\n",
      "TARGET RANK: 3\n",
      "============================================================\n",
      "Group: [105, 305, 477]\n",
      "Target #3: Strangers on a Train (1951)\n",
      "\n",
      "============================================================\n",
      "Grow & Prune Algorithm\n",
      "============================================================\n",
      "Candidate items: 1275\n",
      "\n",
      "============================================================\n",
      "Pareto Filtering\n",
      "============================================================\n",
      "Initial candidates: 1275\n",
      "\n",
      "Step 1: Pre-filtering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing basic metrics: 100%|████████████| 1275/1275 [00:01<00:00, 1231.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pre-filtering: 345 items\n",
      "Limited to top-50: 50 items\n",
      "\n",
      "Step 2: Computing influence & explanatory power...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing metrics: 100%|███████████████████████| 50/50 [00:00<00:00, 696.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Pareto filtering...\n",
      "After Pareto: 4 items\n",
      "\n",
      "============================================================\n",
      "GROW Phase\n",
      "============================================================\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "+ Added: WALL·E (2008)\n",
      "  Metrics: rec=1.00, rate=5.00, infl=4.03, exp=1.000\n",
      "  Size: 1, Fairness: 1.00, Valid: False\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "+ Added: Death Proof (2007)\n",
      "  Metrics: rec=0.67, rate=4.75, infl=4.12, exp=0.633\n",
      "  Size: 2, Fairness: 1.00, Valid: False\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "+ Added: Thing, The (1982)\n",
      "  Metrics: rec=0.67, rate=5.00, infl=4.06, exp=0.506\n",
      "  Size: 3, Fairness: 1.00, Valid: False\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "+ Added: Green Mile, The (1999)\n",
      "  Metrics: rec=0.67, rate=5.00, infl=4.12, exp=0.268\n",
      "  Size: 4, Fairness: 1.00, Valid: False\n",
      "\n",
      "⚠ No valid counterfactual found\n",
      "\n",
      "---- Explanation ----\n",
      "⚠ No valid explanation found\n",
      "\n",
      "============================================================\n",
      "TARGET RANK: 4\n",
      "============================================================\n",
      "Group: [105, 305, 477]\n",
      "Target #4: Hoop Dreams (1994)\n",
      "\n",
      "============================================================\n",
      "Grow & Prune Algorithm\n",
      "============================================================\n",
      "Candidate items: 1275\n",
      "\n",
      "============================================================\n",
      "Pareto Filtering\n",
      "============================================================\n",
      "Initial candidates: 1275\n",
      "\n",
      "Step 1: Pre-filtering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing basic metrics: 100%|████████████| 1275/1275 [00:00<00:00, 1276.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pre-filtering: 345 items\n",
      "Limited to top-50: 50 items\n",
      "\n",
      "Step 2: Computing influence & explanatory power...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing metrics: 100%|███████████████████████| 50/50 [00:00<00:00, 690.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Pareto filtering...\n",
      "After Pareto: 6 items\n",
      "\n",
      "============================================================\n",
      "GROW Phase\n",
      "============================================================\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "+ Added: Boondock Saints, The (2000)\n",
      "  Metrics: rec=1.00, rate=4.67, infl=4.02, exp=0.933\n",
      "  Size: 1, Fairness: 1.00, Valid: False\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "+ Added: Snatch (2000)\n",
      "  Metrics: rec=0.67, rate=5.00, infl=4.11, exp=0.578\n",
      "  Size: 2, Fairness: 1.00, Valid: False\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "+ Added: Requiem for a Dream (2000)\n",
      "  Metrics: rec=0.67, rate=4.75, infl=4.11, exp=0.633\n",
      "  Size: 3, Fairness: 1.00, Valid: True\n",
      "  ✓ Valid counterfactual found\n",
      "\n",
      "============================================================\n",
      "PRUNE Phase\n",
      "============================================================\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  ✓ Kept: Boondock Saints, The (2000) (necessary for validity)\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  ✓ Kept: Snatch (2000) (necessary for validity)\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  ✓ Kept: Requiem for a Dream (2000) (necessary for validity)\n",
      "\n",
      "---- Explanation ----\n",
      "If NOT watched: 3 items → 'Hoop Dreams (1994)' disappears\n",
      "\n",
      "1. Boondock Saints, The (2000)\n",
      "2. Snatch (2000)\n",
      "3. Requiem for a Dream (2000)\n",
      "\n",
      "============================================================\n",
      "TARGET RANK: 5\n",
      "============================================================\n",
      "Group: [105, 305, 477]\n",
      "Target #5: Return of the Pink Panther, The (1975)\n",
      "\n",
      "============================================================\n",
      "Grow & Prune Algorithm\n",
      "============================================================\n",
      "Candidate items: 1275\n",
      "\n",
      "============================================================\n",
      "Pareto Filtering\n",
      "============================================================\n",
      "Initial candidates: 1275\n",
      "\n",
      "Step 1: Pre-filtering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing basic metrics: 100%|████████████| 1275/1275 [00:01<00:00, 1246.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pre-filtering: 345 items\n",
      "Limited to top-50: 50 items\n",
      "\n",
      "Step 2: Computing influence & explanatory power...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing metrics: 100%|███████████████████████| 50/50 [00:00<00:00, 697.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Pareto filtering...\n",
      "After Pareto: 5 items\n",
      "\n",
      "============================================================\n",
      "GROW Phase\n",
      "============================================================\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "+ Added: Inception (2010)\n",
      "  Metrics: rec=1.00, rate=4.83, infl=4.01, exp=0.849\n",
      "  Size: 1, Fairness: 1.00, Valid: False\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "\n",
      "+ Added: WALL·E (2008)\n",
      "  Metrics: rec=1.00, rate=5.00, infl=4.01, exp=0.727\n",
      "  Size: 2, Fairness: 1.00, Valid: True\n",
      "  ✓ Valid counterfactual found\n",
      "\n",
      "============================================================\n",
      "PRUNE Phase\n",
      "============================================================\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  ✓ Kept: Inception (2010) (necessary for validity)\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "  ✓ Kept: WALL·E (2008) (necessary for validity)\n",
      "\n",
      "---- Explanation ----\n",
      "If NOT watched: 2 items → 'Return of the Pink Panther, The (1975)' disappears\n",
      "\n",
      "1. Inception (2010)\n",
      "2. WALL·E (2008)\n",
      "\n",
      "============================================================\n",
      "TARGET RANK: 6\n",
      "============================================================\n",
      "Group: [105, 305, 477]\n",
      "Target #6: Bowfinger (1999)\n",
      "\n",
      "============================================================\n",
      "Grow & Prune Algorithm\n",
      "============================================================\n",
      "Candidate items: 1275\n",
      "\n",
      "============================================================\n",
      "Pareto Filtering\n",
      "============================================================\n",
      "Initial candidates: 1275\n",
      "\n",
      "Step 1: Pre-filtering...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing basic metrics: 100%|████████████| 1275/1275 [00:00<00:00, 1284.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After pre-filtering: 345 items\n",
      "Limited to top-50: 50 items\n",
      "\n",
      "Step 2: Computing influence & explanatory power...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing metrics: 100%|███████████████████████| 50/50 [00:00<00:00, 691.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Pareto filtering...\n",
      "After Pareto: 6 items\n",
      "\n",
      "============================================================\n",
      "GROW Phase\n",
      "============================================================\n",
      "Computing the pearson similarity matrix...\n",
      "Done computing similarity matrix.\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# 5.2: Run ALL target ranks 1–10 automatically \n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Running Counterfactual Explanations for Rank 1–10\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = []  # store results for summary table\n",
    "\n",
    "explainer = GroupCounterfactualExplainer(\n",
    "    ratings_df=ratings,\n",
    "    movies_df=movies,\n",
    "    base_recommender=recommender\n",
    ")\n",
    "\n",
    "for target_rank in range(1, 11):  # rank 1 to 10\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"TARGET RANK: {target_rank}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    target_movie_id = recommendations[target_rank - 1][0]\n",
    "    target_title = movies.loc[movies[\"movieId\"] == target_movie_id, \"title\"].values[0]\n",
    "\n",
    "    print(f\"Group: {test_group}\")\n",
    "    print(f\"Target #{target_rank}: {target_title}\")\n",
    "\n",
    "    explanation, metrics = explainer.grow_and_prune(\n",
    "        group_ids=test_group,\n",
    "        target_id=target_movie_id,\n",
    "        original_list=recommendations,\n",
    "        max_size=8,\n",
    "        use_pareto=True\n",
    "    )\n",
    "\n",
    "    # --- Safe summary to avoid KeyError ---\n",
    "    results.append({\n",
    "        \"rank\": target_rank,\n",
    "        \"movie\": target_title,\n",
    "        \"valid\": metrics.get(\"valid\", False),\n",
    "        \"size\": metrics.get(\"size\", None),\n",
    "        \"fairness\": metrics.get(\"fairness\", None),\n",
    "        \"exp_power\": metrics.get(\"avg_exp_power\", 0.0),\n",
    "        \"influence\": metrics.get(\"avg_influence\", 0.0),\n",
    "        \"explanation\": explanation\n",
    "    })\n",
    "\n",
    "    # Print explanation nicely\n",
    "    print(\"\\n---- Explanation ----\")\n",
    "    if not metrics.get(\"valid\", False):\n",
    "        print(\"⚠ No valid explanation found\")\n",
    "    else:\n",
    "        print(f\"If NOT watched: {len(explanation)} items → '{target_title}' disappears\\n\")\n",
    "        for i, mid in enumerate(explanation, 1):\n",
    "            title = movies.loc[movies[\"movieId\"] == mid, \"title\"].values[0]\n",
    "            print(f\"{i}. {title}\")\n",
    "\n",
    "# ============================================================\n",
    "# Final Summary Table\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY RESULTS FOR RANK 1–10\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "for r in results:\n",
    "    print(f\"Rank {r['rank']}: {r['movie']}\")\n",
    "    print(f\"  Valid: {r['valid']},  Size: {r['size']},  Exp-power: {r['exp_power']:.3f}\")\n",
    "    print(f\"  Influence: {r['influence']:.3f}, Fairness: {r['fairness']}\")\n",
    "    print(f\"  Items: {r['explanation']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddc04c5-26ef-4187-b65c-f1bb68e7ea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# 6: Visualization of Results\n",
    "# ============================================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Generating Visualizations\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Prepare data\n",
    "valid_results = [r for r in results if r['valid']]\n",
    "failed_results = [r for r in results if not r['valid']]\n",
    "\n",
    "# ============================================================\n",
    "# Figure 1: Success Rate and Explanation Size\n",
    "# ============================================================\n",
    "\n",
    "fig1, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig1.suptitle('Counterfactual Explanation: Success Rate & Size', \n",
    "              fontsize=14, fontweight='bold', y=1.02)\n",
    "\n",
    "# Left: Success Rate (Pie chart )\n",
    "sizes_pie = [len(valid_results), len(failed_results)]\n",
    "colors_pie = ['#3498db', '#95a5a6']\n",
    "explode = (0.05, 0)\n",
    "\n",
    "ax1.pie(sizes_pie, explode=explode, labels=['Valid', 'Failed'], \n",
    "        colors=colors_pie, autopct='%1.0f%%', startangle=90,\n",
    "        textprops={'fontsize': 12, 'fontweight': 'bold'})\n",
    "ax1.set_title(f'Success Rate: {len(valid_results)}/10 Targets', \n",
    "             fontsize=12, fontweight='bold', pad=10)\n",
    "\n",
    "# Right: Explanation Size\n",
    "if valid_results:\n",
    "    sizes = [r['size'] for r in valid_results]\n",
    "    ranks = [r['rank'] for r in valid_results]\n",
    "    \n",
    "    bars = ax2.bar(range(len(sizes)), sizes, color='#3498db', alpha=0.8, edgecolor='black')\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for i, (bar, size) in enumerate(zip(bars, sizes)):\n",
    "        height = bar.get_height()\n",
    "        ax2.text(bar.get_x() + bar.get_width()/2., height + 0.05,\n",
    "                f'{int(size)}',\n",
    "                ha='center', va='bottom', fontweight='bold', fontsize=10)\n",
    "    \n",
    "    ax2.set_xlabel('Target Rank', fontsize=11, fontweight='bold')\n",
    "    ax2.set_ylabel('Number of Items', fontsize=11, fontweight='bold')\n",
    "    ax2.set_title('Explanation Size (Items Needed)', fontsize=12, fontweight='bold', pad=10)\n",
    "    ax2.set_xticks(range(len(sizes)))\n",
    "    ax2.set_xticklabels([f\"#{r}\" for r in ranks], fontsize=10)\n",
    "    ax2.set_ylim(0, max(sizes) + 0.5)\n",
    "    ax2.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax2.set_axisbelow(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n Figure 1: Success rate shows 60% of targets can be explained\")\n",
    "print(f\" Explanation sizes range from {min([r['size'] for r in valid_results])} to {max([r['size'] for r in valid_results])} items\")\n",
    "\n",
    "# ============================================================\n",
    "# Figure 2: Fairness and Explanatory Power\n",
    "# ============================================================\n",
    "\n",
    "fig2, (ax3, ax4) = plt.subplots(1, 2, figsize=(14, 5))\n",
    "fig2.suptitle('Counterfactual Explanation: Quality Metrics', \n",
    "              fontsize=14, fontweight='bold', y=1.02)\n",
    "\n",
    "if valid_results:\n",
    "    fairness_scores = [r['fairness'] for r in valid_results]\n",
    "    exp_powers = [r['exp_power'] for r in valid_results]\n",
    "    ranks = [r['rank'] for r in valid_results]\n",
    "    \n",
    "    # Left: Fairness\n",
    "    bars_fair = ax3.bar(range(len(fairness_scores)), fairness_scores, \n",
    "                        color='#3498db', alpha=0.8, edgecolor='black')\n",
    "    \n",
    "    # Color perfect fairness differently\n",
    "    for i, (bar, score) in enumerate(zip(bars_fair, fairness_scores)):\n",
    "        if score == 1.0:\n",
    "            bar.set_color('#27ae60')\n",
    "    \n",
    "    ax3.axhline(y=0.67, color='#e74c3c', linestyle='--', linewidth=2, \n",
    "               label='Minimum Threshold (0.67)', zorder=0)\n",
    "    ax3.axhline(y=1.0, color='#27ae60', linestyle=':', linewidth=1.5, \n",
    "               label='Perfect Fairness (1.0)', alpha=0.5, zorder=0)\n",
    "    \n",
    "    ax3.set_xlabel('Target Rank', fontsize=11, fontweight='bold')\n",
    "    ax3.set_ylabel('Fairness Score', fontsize=11, fontweight='bold')\n",
    "    ax3.set_title('Fairness: Group Member Coverage', fontsize=12, fontweight='bold', pad=10)\n",
    "    ax3.set_xticks(range(len(fairness_scores)))\n",
    "    ax3.set_xticklabels([f\"#{r}\" for r in ranks], fontsize=10)\n",
    "    ax3.set_ylim(0, 1.15)\n",
    "    ax3.legend(loc='lower right', fontsize=9)\n",
    "    ax3.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax3.set_axisbelow(True)\n",
    "    \n",
    "    # Right: Explanatory Power (ORANGE)\n",
    "    bars_exp = ax4.bar(range(len(exp_powers)), exp_powers, \n",
    "                      color='#e67e22', alpha=0.8, edgecolor='black')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, (bar, power) in enumerate(zip(bars_exp, exp_powers)):\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., height + 0.02,\n",
    "                f'{power:.2f}',\n",
    "                ha='center', va='bottom', fontweight='bold', fontsize=9)\n",
    "    \n",
    "    ax4.set_xlabel('Target Rank', fontsize=11, fontweight='bold')\n",
    "    ax4.set_ylabel('Explanatory Power', fontsize=11, fontweight='bold')\n",
    "    ax4.set_title('Explanatory Power: Strength of Explanation', fontsize=12, fontweight='bold', pad=10)\n",
    "    ax4.set_xticks(range(len(exp_powers)))\n",
    "    ax4.set_xticklabels([f\"#{r}\" for r in ranks], fontsize=10)\n",
    "    ax4.set_ylim(0, 1.15)\n",
    "    ax4.grid(axis='y', alpha=0.3, linestyle='--')\n",
    "    ax4.set_axisbelow(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n Figure 2: {sum(f == 1.0 for f in fairness_scores)}/{len(fairness_scores)} explanations achieve perfect fairness\")\n",
    "print(f\" Explanatory power ranges from {min(exp_powers):.3f} to {max(exp_powers):.3f}\")\n",
    "\n",
    "# ============================================================\n",
    "# Summary Statistics\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "if valid_results:\n",
    "    sizes = [r['size'] for r in valid_results]\n",
    "    fairness = [r['fairness'] for r in valid_results]\n",
    "    exp_power = [r['exp_power'] for r in valid_results]\n",
    "    \n",
    "    print(f\"\\nValid Explanations: {len(valid_results)}/10 ({len(valid_results)*10}%)\")\n",
    "    print(f\"\\nExplanation Size:\")\n",
    "    print(f\"  Mean: {np.mean(sizes):.2f} items\")\n",
    "    print(f\"  Range: {min(sizes)} - {max(sizes)} items\")\n",
    "    \n",
    "    print(f\"\\nFairness Score:\")\n",
    "    print(f\"  Mean: {np.mean(fairness):.2f}\")\n",
    "    print(f\"  Perfect (1.0): {sum(f == 1.0 for f in fairness)}/{len(fairness)}\")\n",
    "    print(f\"  All above threshold (≥0.67): {sum(f >= 0.67 for f in fairness)}/{len(fairness)}\")\n",
    "    \n",
    "    print(f\"\\nExplanatory Power:\")\n",
    "    print(f\"  Mean: {np.mean(exp_power):.3f}\")\n",
    "    print(f\"  Range: {min(exp_power):.3f} - {max(exp_power):.3f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "342fec03-dda2-42a5-a5aa-2cda63ad3d43",
   "metadata": {},
   "source": [
    "## Step 3: Results & Conclusion\n",
    "\n",
    "### Experimental Setup\n",
    "- **Dataset:** MovieLens 100K (100,836 ratings, 610 users, 9,724 movies)\n",
    "- **Test Group:** Users [105, 305, 477] (3 members, 81 common high-rated movies)\n",
    "- **Recommender:** Item-based KNN with Pearson similarity (k=50, RMSE=0.9700)\n",
    "- **Candidates:** Movies rated ≥3.5 by any group member (~1275 items)\n",
    "- **Pareto Filtering:** Pre-filter (recognition≥0.5, rating≥3.5) → top-50 → Pareto (3-5 items)\n",
    "\n",
    "### Results Visualization\n",
    "\n",
    "**Figure 1: Success Rate & Explanation Size**\n",
    "- **Left:** Success rate is 60% (6/10 targets explained)\n",
    "- **Right:** Explanation sizes range from 1-3 items\n",
    "  - Rank 4: 3 items\n",
    "  - Rank 5: 2 items\n",
    "  - Ranks 7, 8, 9, 10: 1 item each\n",
    "\n",
    "**Figure 2: Quality Metrics**\n",
    "- **Left (Fairness):** 5/6 explanations achieve perfect fairness (1.0)\n",
    "  - Only Rank 8 has 0.67 (still above minimum threshold)\n",
    "- **Right (Explanatory Power):** Range from 0.580 to 0.967\n",
    "  - Higher values indicate stronger causal links\n",
    "\n",
    "**Statistical Summary:**\n",
    "- Explanation Size: Mean=1.50, Range=[1, 3]\n",
    "- Fairness: Mean=0.94, Perfect (1.0)=5/6, All ≥0.67=6/6\n",
    "- Explanatory Power: Mean=0.725, Range=[0.580, 0.967]\n",
    "\n",
    "### Detailed Results\n",
    "\n",
    "**Valid Explanations (6/10):**\n",
    "\n",
    "| Rank | Target Movie | Size | Explanation Items (movieId) | Fairness | Exp Power |\n",
    "|------|-------------|------|---------------------------|----------|-----------|\n",
    "| 4 | Hoop Dreams (1994) | 3 | [3275, 4011, 3949] | 1.0 | 0.715 |\n",
    "| 5 | Return of the Pink Panther (1975) | 2 | [79132, 60069] | 1.0 | 0.788 |\n",
    "| 7 | Being There (1979) | 1 | [48516] | 1.0 | 0.967 |\n",
    "| 8 | Elf (2003) | 1 | [92259] | 0.67 | 0.603 |\n",
    "| 9 | Gods Must Be Crazy (1980) | 1 | [1193] | 1.0 | 0.697 |\n",
    "| 10 | Like Water for Chocolate (1992) | 1 | [1222] | 1.0 | 0.580 |\n",
    "\n",
    "**Failed Cases (4/10):**\n",
    "- Ranks 1, 2, 3, 6: No valid explanation found within max_size=8\n",
    "- Top-ranked items involve complex multi-factor reasoning beyond simple explanations\n",
    "\n",
    "### Example Explanation\n",
    "\n",
    "**Target:** Like Water for Chocolate (Rank 10)\n",
    "\n",
    "**Counterfactual Statement:**\n",
    "```\n",
    "\"If the group had not watched Full Metal Jacket (U105:4.0★, U305:5.0★, U477:5.0★), \n",
    "then Like Water for Chocolate would not be recommended.\"\n",
    "```\n",
    "\n",
    "**Interpretation:**\n",
    "- Single-item explanation with perfect fairness (all 3 members rated it)\n",
    "- High group rating (4.67 average) indicates strong consensus\n",
    "- Explanatory power of 0.580 shows moderate causal link through item-item similarity\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Pareto Filtering Effectiveness:** Reduced candidates from 1,275 → 345 (pre-filter) → 50 (top-K) → 3-5 (Pareto), achieving 99.6% reduction\n",
    "\n",
    "2. **Fairness Achievement:** All valid explanations meet threshold (≥0.67), with 5/6 achieving perfect fairness (1.0)\n",
    "\n",
    "3. **Minimality:** Mean size of 1.50 items demonstrates high conciseness\n",
    "\n",
    "4. **Rank Pattern:** Lower ranks (7-10) easier to explain with single items; higher ranks (4-5) need 2-3 items\n",
    "\n",
    "5. **Computational Efficiency:** Fast explanatory power approximation reduced runtime \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a963a1-5a4a-45e2-b01b-8568acbcf53d",
   "metadata": {},
   "source": [
    "# Step 4: Presentation (5 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98d3293-8acb-4b43-8495-aa91098dd36c",
   "metadata": {},
   "source": [
    "5 slides (Done)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
